{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e7ecfa-f5fe-4c60-8b49-b9ab6891fb2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import openpyxl\n",
    "from openpyxl import load_workbook\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, KFold, cross_val_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, cohen_kappa_score, confusion_matrix, classification_report\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704b4347-6b29-4016-bc1a-7a08b69deea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Excel File\n",
    "INPUT_DATA_EXCEL_FILE_NAME = r\"ResumeDataSet_BrandNew.xlsx\"\n",
    "WORKSHEET_NAME = r\"ResumeDataSet\"\n",
    "data = pd.read_excel(INPUT_DATA_EXCEL_FILE_NAME, sheet_name=WORKSHEET_NAME)\n",
    "\n",
    "# Data cleaning functions (you've already defined these earlier)\n",
    "def preprocess_text(text):\n",
    "    # Perform the text preprocessing steps you want (e.g., removing special characters, stopwords, etc.)\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\x00-\\x7F]+', ' ', text)\n",
    "    text = ' '.join([word for word in text.split() if word not in stopwords.words('english')])\n",
    "    return text\n",
    "\n",
    "# Apply text cleaning function to the 'Resume' column\n",
    "data['CleanDescription'] = data['Resume'].apply(preprocess_text)\n",
    "\n",
    "# If you want to verify the cleaned text\n",
    "print(data[['Resume', 'CleanDescription']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4c1403-43b9-4a6a-be0d-78cdfbd6fc20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert raw text into a matrix of features using TF-IDF vectorizer\n",
    "tfidf = TfidfVectorizer(ngram_range=(2, 4))  # You can adjust n-grams as per your project\n",
    "X = tfidf.fit_transform(data['CleanDescription'])\n",
    "y = data['Category']  # Assuming the target column is 'Category'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f0bb41-cdfe-4f5d-b679-ac5509dd1deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93bda9b-2319-430a-8d77-7739d432de2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter Tuning using RandomizedSearchCV for Logistic Regression\n",
    "param_dist = {\n",
    "    'C': np.linspace(0.01, 1, 100),\n",
    "    'max_iter': [100, 200, 300, 400],\n",
    "    'penalty': ['l2', 'l1']\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(LogisticRegression(), param_distributions=param_dist, n_iter=100, cv=3, n_jobs=-1, random_state=42)\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Best Model\n",
    "ModelLrg = random_search.best_estimator_\n",
    "\n",
    "# Print Best Hyperparameters\n",
    "print(\"Best params:\", random_search.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26443b3-5fa0-4214-b963-253666586767",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model\n",
    "ModelLrg.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels on test data\n",
    "y_pred = ModelLrg.predict(X_test)\n",
    "\n",
    "# Evaluate model performance\n",
    "print(\"Accuracy Score:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Cohen Kappa Score:\", cohen_kappa_score(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef7516e-5b19-429e-9d50-f9d8b1443a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation using KFold\n",
    "cv = KFold(n_splits=10, random_state=42, shuffle=True)\n",
    "cv_scores = cross_val_score(ModelLrg, X, y, cv=cv, scoring='accuracy')\n",
    "print(\"Cross-validation accuracy:\", cv_scores.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea73cce-4eac-4b5f-ae1c-eff5106d2cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the model\n",
    "with open(\"model.pkl\", 'wb') as file:\n",
    "    pickle.dump(ModelLrg, file)\n",
    "\n",
    "# Load the model for future predictions\n",
    "with open(\"model.pkl\", 'rb') as file:\n",
    "    loaded_model = pickle.load(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695d33b5-511d-42cd-97fe-fe70c5283275",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate WordCloud for important words\n",
    "text = \" \".join(data['CleanDescription'])\n",
    "wc = WordCloud(background_color='white', max_words=200).generate(text)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(wc, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5314ec43-7452-4722-a183-2b6a44488284",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model on new text data\n",
    "new_text = \"Some resume content for prediction\"\n",
    "new_vector = tfidf.transform([new_text])\n",
    "prediction = loaded_model.predict(new_vector)\n",
    "print(\"Predicted Class:\", prediction)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
