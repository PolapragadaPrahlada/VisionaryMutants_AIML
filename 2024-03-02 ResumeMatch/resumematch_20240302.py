# -*- coding: utf-8 -*-
"""ResumeMatch_20240302.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ZQUbkeJZzBky4clxwyVKpgEJZE4vMiZ7

# <font color=Blue size="6">Resume Match</font>
<hr size="100" noshade>

## <font color="Black">Contents</font>
> <a href="#Step_AA">Concepts Used in this Project.</a><br>
> - <a href="#Step_AA_01">01. Types of Text Classification.</a><br>
> - <a href="#Step_AA_02">02. Performace Metrics.</a><br>
> - <a href="#Step_AA_03">03. Count Vectorizer Vs TFIDF Vectorizer.</a><br>
>   - <a href="#Step_AA_03_CV">Count Vectorizer.</a><br>
>   - <a href="#Step_AA_03_TV">TF-IDF Vectorizer.</a><br>
> - <a href="#Step_AA_04">04. N-Gram.</a><br>

> <a href="#Step_00">Step-00: Crucial Python Modules of the Project.</a><br>
> - <a href="#Step_00_Py">Python Libraries.</a><br>
> - <a href="#Step_00_Co">Constants.</a><br>
> - <a href="#Step_00_Va">Variables.</a><br>
> - <a href="#Step_00_Ma">Main Code.</a><br>

> <a href="#Step_01">Step-01: Global Functions.</a><br>
> - <a href="#Step_01_Py">Python Libraries.</a><br>
> - <a href="#Step_01_Co">Constants.</a><br>
> - <a href="#Step_01_Va">Variables.</a><br>
> - <a href="#Step_01_Ma">Main Code.</a><br>

> <a href="#Step_02">Step-02: Managing the Data.</a><br>
> - <a href="#Step_02_Py">Python Libraries.</a><br>
> - <a href="#Step_02_Co">Constants.</a><br>
> - <a href="#Step_02_Va">Variables.</a><br>
> - <a href="#Step_02_Ma">Main Code.</a><br>

> <a href="#Step_03">Step-03: Processing the Data.</a><br>
> - <a href="#Step_03_Py">Python Libraries.</a><br>
> - <a href="#Step_03_Co">Constants.</a><br>
> - <a href="#Step_03_Va">Variables.</a><br>
> - <a href="#Step_03_Ma">Main Code.</a><br>
>   - <a href="#Step_03_Manage">Manage Common Words Between/Among Classes.</a><br>

> <a href="#Step_04">Step-04: Visualizing the Data.</a><br>
> - <a href="#Step_04_Py">Python Libraries.</a><br>
> - <a href="#Step_04_Co">Constants.</a><br>
> - <a href="#Step_04_Va">Variables.</a><br>
> - <a href="#Step_04_Ma">Main Code.</a><br>
>   - <a href="#Step_04_Cleaning">Cleaning-up the Data with the Help of Visualization.</a><br>

> <a href="#Step_05">Step-05: Vectorizing the Data.</a><br>
> - <a href="#Step_05_Py">Python Libraries.</a><br>
> - <a href="#Step_05_Co">Constants.</a><br>
> - <a href="#Step_05_Va">Variables.</a><br>
> - <a href="#Step_05_Ma">Main Code.</a><br>
>   - <a href="#Step_05_Word2Vec">01. Word2Vec Vectorizer.</a><br>
>   - <a href="#Step_05_Glove">02. Glove Vectorizer.</a><br>
>   - <a href="#Step_05_CV">03. Count Vectorizer.</a><br>
>   - <a href="#Step_05_TV">04. TF-IDF Vectorizer.</a><br>

> <a href="#Step_06">Step-06: Feature Selection.</a><br>
> - <a href="#Step_06_Py">Python Libraries.</a><br>
> - <a href="#Step_06_Co">Constants.</a><br>
> - <a href="#Step_06_Va">Variables.</a><br>
> - <a href="#Step_06_Ma">Main Code.</a><br>

> <a href="#Step_07">Step-07: AIML Model.</a><br>
> - <a href="#Step_07_Py">Python Libraries.</a><br>
> - <a href="#Step_07_Co">Constants.</a><br>
> - <a href="#Step_07_Va">Variables.</a><br>
> - <a href="#Step_07_Ma">Main Code.</a><br>
>   - <a href="#Step_07_ModelLrg">01. [Base Model] Logistic Regression with RandomizedSearchCV.</a><br>
>   - <a href="#Step_07_ModelMnb">02. [Base Model] Multinomial Naive Bayes with RandomizedSearchCV.</a><br>
>   - <a href="#Step_07_ModelSgd">03. [Base Model] SDGClassifier with Hinge Loss -> SVM.</a><br>
>   - <a href="#Step_07_ModelDtc">04. [Base Model] Decision Tree Classifier with RandomizedSearchCV.</a><br>
>   - <a href="#Step_07_ModelKnn">05. [Base Model] k-Nearest Neighbors (k-NN) Classifier with RandomizedSearchCV.</a><br>
>   - <a href="#Step_07_ModelSvm">06. [Base Model] Support Vector Machine (SVM) Classifier.</a><br>
>   - <a href="#Step_07_ModelSvc">07. [Ensemble Method] Soft Voting Classifier.</a><br>
>   - <a href="#Step_07_ModelStk">08. [Ensemble Method] Stacking Classifier with XGBClassifier as the "Final Estimator" or "Meta Learner".</a><br>
>   - <a href="#Step_07_MC">Model Comparision.</a><br>
>   - <a href="#Step_07_CO">Check for Overfitting.</a><br>

> <a href="#Step_08">Step-08: AIML Model Testing.</a><br>
> - <a href="#Step_08_Py">Python Libraries.</a><br>
> - <a href="#Step_08_Co">Constants.</a><br>
> - <a href="#Step_08_Va">Variables.</a><br>
> - <a href="#Step_08_Ma">Main Code.</a><br>
>   - <a href="#Step_08_C01">Case-01: Testing with Test Data.</a><br>
>   - <a href="#Step_08_C02">Case-02: Testing with Brand New Data.</a><br>

> <a href="#Step_09">Step-09: Deployment Process.</a><br>

> <a href="#Step_10">Step-10: Windows GUI Application.</a><br>
> - <a href="#Step_10_Py">Python Libraries.</a><br>
> - <a href="#Step_10_Co">Constants.</a><br>
> - <a href="#Step_10_Va">Variables.</a><br>
> - <a href="#Step_10_Ma">Main Code.</a><br>
>   - <a href="#Step_10_LocalUdfs">Local User Defined Functions (UDFs).</a><br>

<a id=Step_AA></a>

# <font color=#7F7F7f size="6">Concepts Used in this Project.</font>

<a id=Step_AA_01></a>

### <font color=Red>01. Types of Text Classification.</font>

* Text classification is one of the fundamental tasks in natural language processing with broad applications such as:
  * Topic Labeling: Another common example of text classification is topic labeling that is, understanding what a given text is talking about. It’s often used for structuring and organizing data, such as organizing customer feedback by topic or organizing news articles by subject.
  * Intent detection: Intent detection or intent classification is another great use case for text classifi cationthat analyzes text to understand the reason behind feedback. Maybe it’s a complaint, ormaybe a customer is expressing intent to purchase a product. It’s used for customerservice, marketing email responses, generating product analytics and automating business practices. Intent detection with machine learning can read emails and chatbotconversations and automatically route them to the correct department. Some of the email intent classifier tags are Interested, Not Interested, Unsubscribe, Wrong Person, Email Bounce
and Autoresponder.
  * Sentiment Analysis: The most popular example of text classification is
sentiment analysis (or) opinion mining. The automated process of reading a text for opinion polarity (positive, negative, neutral and beyond). Companies use sentiment classifiers on a wide range ofapplications like product analytics, brand monitoring, market research, customer support, workforce analytics and much more. Sentiment analysis allows us to automatically analyze all forms of text for the feeling and emotion.
  * Language Detection: Language detection is another great example of text classification that is, the process ofclassifying incoming text according to its language. These text classifiers are often used for routing purposes (e.g., route support tickets according to their language to the appropriate team).
  * Spam Detection.

* Text classification can be done in two ways:
  * Manual: Manual text classification involves a human annotator, who interprets the content of text and categorizes it accordingly. This method can deliver good results but it's time-consuming and expensive.
  * Automatic: Automatic text classification applies Machine Learning,
Natural Language Processing (NLP) and other AI-guided techniques
to automatically classify text in a faster, more cost-eff ective and more accurate manner.

* There are many approaches to automatic text classification but they all fall under three types of systems:
  * Machine Learning-based Systems
  * Rule-based Systems
  * Hybrid Systems

* Machine Learning-based Systems: Machine learning text classification learns to make classifications based on past observations. By using pre-labeled examples as training data, machine learning algorithms can learn the different associations between pieces of text and that a particular output (i.e., tags) is expected for a particular input(i.e., text). A “tag” is the pre-determined classification or category that any given text could fall into.

  For example, if we have defined our dictionary to have the following words {This, is, the, not, awesome, bad, basketball}, and we wanted to vectorize the text “This is awesome”, we would have the following vector representation of that text: (1, 1, 0, 0, 1, 0, 0). Then, the machine learning algorithm is fed with training data that consists of pairs offeature sets (vectors for each text example) and tags (e.g. sports, politics) to produce aclassification model.

* Text Classifi cation with Python: Python is usually the programming language of choice for developers and data scientist swho work with machine learning models. The simple syntax, its massive community and the scientific-computing friendliness of its mathematical libraries are some of the reasonswhy Python is so prevalent in the field.  Following are the popular Python libraries used in text classification:
  * Scikit-learn
  * NLTK
  * SpaCy
  * TensorFlow
  * PyTorch

* Link(s):<br>
  https://monkeylearn.com/text-classification/

* Multi-Class Classification: In multi-class classification, each input will have only one output class. For example, if we are building an animal classifier that classifies among Dog, Rabbit, Cat and Tiger, it makes sense only for one of these classes to be selected each time.
* Multi-Label Classification: In multi-label classification, each input can have multi-output classes. For example, if we are building a model which predicts all the clothing articles a person is wearing, we can use a multi-label
classification model since there can be more than one possible option at once i.e. a person can wear multiple clothing articles at a given point of time.
* Link(s):<br>
  https://www.analyticsvidhya.com/blog/2021/07/demystifying-the-difference-between-multi-class-and-multi-label-classification-problem-statements-in-deep-learning/

<a id=Step_AA_02></a>

### <font color=Red>02. Performace Metrics.</font>

##### <b>Performace Metrics:</b>
* To evaluate the performance of a classifier, the following metrics are used:
  1. Confusion matrix
  2. Accuracy
  3. Precision
  4. Recall
  5. F1-Score

##### <b>1. Confusion matrix:</b>
* A Confusion matrix is an N x N matrix used for evaluating the performance of a classification model, where N is the number of target classes. The matrix compares the actual target values with those predicted by the machine learning model. This gives us a holistic view of how well our classification model is performing and what kinds of errors it is making.
* For a binary classification problem, we would have a 2 x 2 matrix. For a multi-class classification problem, we would have a N x N matrix.
* A Confusion matrix has the below with 4 values:
  * <b>True Positive (TP):</b>
    * The actual label of the given instance is Positive.
    * The classifier also predicts it as Positive.
  * <b>True Negative (TN):</b>
    * The actual label of the given instance is Negative.
    * The classifier also predicts it as Negative.
  * <b>False Positive (FP):</b>
    * The actual label of the given instance is Negative.
    * The classifier incorrectly predicts it as Positive.
    * Also called as 'Type 1 Error'.
  * <b>False Negative (FN):</b>
    * The actual label of the given instance is Positive.
    * The classifier incorrectly predicts it as Negative.
    * Also called as 'Type 2 Error'.

##### <b>2. Accuracy:</b>
* Accuracy is the ratio of the number of correct predictions to the total number of input samples.
* Accuracy = $\mathbf{\frac{TP + TN}{TP + TN + FP + FN}}$

##### <b>3. Precision:</b>
* Precision tells us how many of the correctly predicted cases actually turned out to be positive.
* Precision is a useful metric in cases where False Positive is a higher concern than False Negatives.
* Precision is important in music or video recommendation systems, e-commerce websites, etc. Wrong results could lead to customer churn and be harmful to the business.
* Precision = $\mathbf{\frac{TP}{TP + FP}}$

##### <b>4. Recall:</b>
* Recall tells us how many of the actual positive cases we were able to predict correctly with our model.
* Recall is a useful metric in cases where False Negative trumps False Positive.
* Recall is important in medical cases where it doesn’t matter whether we raise a false alarm but the actual positive cases should not go undetected!
* Recall = $\mathbf{\frac{TP}{TP + FN}}$

##### <b>5. F1-Score:</b>
* In practice, when we try to increase the Precision of our model, the Recall goes down and vice-versa. The F1-score captures both the trends in a single value.
* F1-score is a harmonic mean of Precision and Recall, and so it gives a combined idea about these two metrics. It is maximum when Precision is equal to Recall.
* There is a catch here. The interpretability of the F1-score is poor. This means that we don’t know what our classifier is maximizing -  Precision or Recall? So, we use it in combination with other evaluation metrics which gives us a complete picture of the result.
* F1-score = $\mathbf{\frac{2 * Precision * Recall}{Precision + Recall}}$

##### <b>Classification Report:</b>
* Classification report is used to measure the quality of predictions from a classification algorithm.
* More specifically, True Positives, False Positives, True Negatives and False Negatives are used to predict the metrics of a classification report as shown below.

<b>Cohen Kappa Score:</b>
* ≤ 0: No agreement.
* 0.01 to 0.20: None to Slight.
* 0.21 to 0.40: Fair.
* 0.41 to 0.60: Moderate
* 0.61 to 0.80: Substantial
* 0.81 to 1.00: Almost perfect agreement.
* Link(s):<br>
  https://en.wikipedia.org/wiki/Cohen%27s_kappa

<a id=Step_AA_03></a>

### <font color=Red>03. Count Vectorizer Vs TFIDF Vectorizer.</font>

<a id=Step_AA_03_CV></a>

#### <font color=Orange>Count Vectorizer.</font>

* Count Vectorizer is a way to convert a given set of strings into a frequency representation.
* The two texts of the following cell can be converted into count frequency using the CountVectorizer function of `sklearn` library.
"""

import warnings
warnings.simplefilter(action='ignore', category=FutureWarning)
import pandas as pd
from sklearn.feature_extraction.text import CountVectorizer as CV

Text1 = "Natural Language Processing is a subfield of AI"
Tag1 = "NLP"

Text2 = "Computer Vision is a subfield of AI"
Tag2 = "CV"

Cv = CV()
Cv.fit([Text1, Text2])

x = Cv.transform([Text1]).toarray()
y = Cv.transform([Text2]).toarray()

Coumns = Cv.get_feature_names()

Df1 = pd.DataFrame(x, columns = Coumns, index = ["Text1"])
Df2 = pd.DataFrame(y, columns = Coumns, index = ["Text2"])

Df = pd.concat([Df1, Df2])

Df["Tag"] = ["NLP", "CV"]

Df

"""* Since `Text1` doesn't contain words `'Computer'` and `'Vision'`, hence their frequencies are calculated as `'0'`. While other words are present once, hence their frequencies are equal to `'1'`.  This is, in a nutshell, how we use Count Vectorizer.
* Count Vectorizer can be helpful in understanding the type of text by the frequency of words in it.  But it's major disadvantages are:
  * It's inability in identifying more important and less important words for analysis.
  * It will just consider words that are abundant in a corpus as the most statistically significant word.
  * It also doesn't identify the relationships between words such as linguistic similarity between words.

<a id=Step_AA_03_TV></a>

#### <font color=Orange>TFIDF Vectorizer.</font>

* TF-IDF means Term Frequency - Inverse Document Frequency. This is a statistic that is based on the frequency of a word in the corpus but it also provides a numerical representation of how important a word is for statistical analysis.
* TF-IDF is better than Count Vectorizers because it not only focuses on the frequency of words present in the corpus but also provides the importance of the words. We can then remove the words that are less important for analysis, hence making the model building less complex by reducing the input dimensions.
* The term "TF" is basically the count of a word in a sentence. for example, in the two examples for Text1, the tf value of the word "subfield" will be 1.
* The term "DF" is called document frequency which means in how many documents the word "subfield" is present within corpus. In our case the corpus consists of Text1 and Text2 (N value is 2) and the word "subfield" is present in both. Hence its df value is 2.
* Also, in the formula, since df is present in the denominator of log (N/df) its called inverse document frequency. Hence the name TF-IDF.
* Here is how we calculate tfidf for a corpus:
"""

import warnings
warnings.simplefilter(action='ignore', category=FutureWarning)
import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer as TV

Text1 = "Natural Language Processing is a subfield of AI"
Tag1 = "NLP"

Text2 = "Computer Vision is a subfield of AI"
Tag2 = "CV"

Tv = TV(norm = None)
Tv.fit([Text1, Text2])

x = Tv.transform([Text1]).toarray()
y = Tv.transform([Text2]).toarray()

Coumns = Tv.get_feature_names()

Df1 = pd.DataFrame(x, columns = Coumns, index = ["Text1"])
Df2 = pd.DataFrame(y, columns = Coumns, index = ["Text2"])

Df = pd.concat([Df1, Df2])

Df["Tag"] = ["NLP", "CV"]

Df

"""* Here, `'sklearn'` calculated the idf value as: `idf = ln[(1+N)/(1+df)]+1`.
* In our example since there are only 2 texts/documents in the corpus, hence N=2. For "Text1" the calculation is:

<img src="01_Input\Support\TFIDF.jpg" align="left" width="475" height="280">

##### Importance of Words:
* TF-IDF is based on the logic that words that are too abundant in a corpus and words that are too rare are both not statistically important for finding a pattern. The Logarithmic factor in TF-IDF mathematically penalizes the words that are too abundant or too rare in the corpus by giving them low TF-IDF scores.
* Higher value of TF-IDF signifies higher importance of the words in the corpus while lower values represent lower importance. In the example the word "AI" is present in both the sentences while words "Natural" and "Computer" are present only in one sentences each. Hence the TF-IDF value of "AI" is lower than the other two. While for the word "Natural" there are more words in Text1 hence its importance is lower than "Computer" since there are less number of words in Text2.
* Even though TF-IDF can provide a good understanding about the importance of words but just like Count Vectors, its disadvantage is:
  * It fails to provide linguistic information about the words such as the real meaning of the words, similarity with other words etc.
* To train a model on the actual linguistic relationship of the words, there are two other word embedding techniques widely used in NLP, they are "word2vec" and "Glove".

* Link(s):<br>
  https://www.linkedin.com/pulse/count-vectorizers-vs-tfidf-natural-language-processing-sheel-saket/
  <br>"2024-03-02 ResumeMatch\nn_Other\Count Vectorizer vs TFIDF Vectorizer _ Natural Language Processing _ LinkedIn.pdf"

<a id=Step_AA_04></a>

### <font color=Red>04. N-Gram.</font>

* <b>ngram_range: tuple (min_n, max_n), default=(1, 1):</b>
  * The lower and upper boundary of the range of n-values for different word n-grams or char n-grams to be extracted.
  * All values of `n` such that `min_n <= n <= max_n` will be used.
  * For example an `ngram_range of (1, 1)` means only unigrams, `ngram_range of (2, 2)` means only bigrams, `ngram_range of (3, 3)` means only trigrams.
  * An `ngram_range of (1, 2)` means unigrams and bigrams, `ngram_range of (2, 3)` means bigrams and trigrams, `ngram_range of (1, 3)` means unigrams, bigrams and trigrams.
  * Only applies if analyzer is not callable.
"""

from sklearn.feature_extraction.text import CountVectorizer
from sklearn.feature_extraction.text import TfidfVectorizer

# Example code to understand N-Grams.
Vectorizer = CountVectorizer(ngram_range=(1, 1))
print("ngram_range=(1, 1): ", end='\n\t')
print(Vectorizer.fit(["an apple a day keeps the doctor away"]).vocabulary_)

# Example code to understand N-Grams.
Vectorizer = CountVectorizer(ngram_range=(2, 2))
print("ngram_range=(2, 2): ", end='\n\t')
print(Vectorizer.fit(["an apple a day keeps the doctor away"]).vocabulary_)

# Example code to understand N-Grams.
Vectorizer = CountVectorizer(ngram_range=(3, 3))
print("ngram_range=(3, 3): ", end='\n\t')
print(Vectorizer.fit(["an apple a day keeps the doctor away"]).vocabulary_)

# Example code to understand N-Grams.
Vectorizer = CountVectorizer(ngram_range=(1, 2))
print("ngram_range=(1, 2): ", end='\n\t')
print(Vectorizer.fit(["an apple a day keeps the doctor away"]).vocabulary_)

# Example code to understand N-Grams.
Vectorizer = CountVectorizer(ngram_range=(2, 3))
print("ngram_range=(2, 3): ", end='\n\t')
print(Vectorizer.fit(["an apple a day keeps the doctor away"]).vocabulary_)

# Example code to understand N-Grams.
Vectorizer = CountVectorizer(ngram_range=(1, 3))
print("ngram_range=(1, 3): ", end='\n\t')
print(Vectorizer.fit(["an apple a day keeps the doctor away"]).vocabulary_)

"""<a href="#Contents" style="float:right">[Contents]</a>

<a id=Step_00></a>

## <font color=Green>Step-00: Crucial Python Modules of the Project.</font>

Note(s):
  * The following code verifies the versions of the crucial Python modules.
  * Not a single module's version should be allowed to change to work this project without an issue.
  * Do NOT execute the next cells even a single module's version shows wrong.

<a id=Step_00_Py></a>

### <font color=Red>Python Libraries.</font>
"""

# Basic imports.
import os
import subprocess

"""<a id=Step_00_Co></a>

### <font color=Red>Constants.</font>
"""

# None.

"""<a id=Step_00_Va></a>

### <font color=Red>Variables.</font>
"""

# Create a list of crucial Python modules whose versions are to be verified.
ModuleVsVersionList = ['jupyter==1.0.0', 'openpyxl==3.0.9', \
                       'nltk==3.7', 'numpy==1.24.1', 'pandas==1.4.2', 'scipy==1.8.1', \
                       'scikit-learn==1.1.1', 'xgboost==1.6.2', \
                       'matplotlib==3.5.2', 'Pillow==9.4.0', 'seaborn==0.11.2', \
                       'wordcloud==1.8.2.2', 'tk==0.1.0', \
                       'fastapi==0.110.1', 'Jinja2==3.0.3', 'python-multipart==0.0.9', 'uvicorn==0.29.0',
                      ]

"""<a id=Step_00_Ma></a>

### <font color=Red>Main Code.</font>
"""

# Verification of versions of the crucial Python modules.

# Iterate through the list of crucial Python modules.
for Idx in range(len(ModuleVsVersionList)):
    # Eexcute the Windows shell command in Jupyter environment.
    # Get the output into variable which will be a Python list.
    CmdStr = "pip freeze | findstr " + ModuleVsVersionList[Idx]
    CmdOutput = subprocess.check_output(CmdStr, shell=True)
    CmdOutput = str(CmdOutput, 'UTF-8').split("\r\n")

    if ModuleVsVersionList[Idx] in CmdOutput:
        print("Module: {:s}, Version is correct.".format(ModuleVsVersionList[Idx]))
    else:
        print("Module: {:s}, Version is correct.".format(ModuleVsVersionList[Idx]))
        assert False, "Module: {:s}, Version is correct.".format(ModuleVsVersionList[Idx])

"""# Notes(s):
#   * Need to check the Python version.
#   * Need to check the pip version.

D:\DataBackup\StudyKit>python
Python 3.10.2 (tags/v3.10.2:a58ebcc, Jan 17 2022, 14:12:15) [MSC v.1929 64 bit (AMD64)] on win32
Type "help", "copyright", "credits" or "license" for more information.

# 'pip' version:
D:\DataBackup\StudyKit>pip show pip
Name: pip
Version: 24.0
Summary: The PyPA recommended tool for installing Python packages.
Home-page:
Author:
Author-email: The pip developers <distutils-sig@python.org>
License: MIT
Location: c:\users\kalyana\appdata\roaming\python\python310\site-packages
Requires:
Required-by:

<a href="#Contents" style="float:right">[Contents]</a>

<a id=Step_01></a>

## <font color=Green>Step-01: Global Functions.</font>

<a id=Step_01_Py></a>

### <font color=Red>Python Libraries.</font>
"""

# None.

"""<a id=Step_01_Co></a>

### <font color=Red>Constants.</font>
"""

# None.

"""<a id=Step_01_Va></a>

### <font color=Red>Variables.</font>
"""

# None.

"""<a id=Step_01_Ma></a>

### <font color=Red>Main Code.</font>
"""

def GetLowerCaseText(Text):
    """
    Definition: User Defined Function (UDF) to clean-up the text.
    Input: Raw text.
    Output: Cleaned-up text.
    """


    # Convert the given text to lower case.
    # Text = [Word.lower() for Word in Text]
    Text = Text.lower()


    return Text

def GetNonasciiFreeText(Text):
    """
    Definition: User Defined Function (UDF) to clean-up the text.
    Input: Raw text.
    Output: Cleaned-up text.
    """


    # Replace all the non-ASCII characters with a space character in the given text.
    Pattern = re.compile(r'[^\x00-\x7F]+', flags=re.I)
    Text = re.sub(Pattern, ' ', Text)


    return Text

def GetSpecialcharFreeText(Text):
    """
    Definition: User Defined Function (UDF) to clean-up the text.
    Input: Raw text.
    Output: Cleaned-up text.
    """


    # Remove all the special characters in the given text.
    for Specialchar in SpecialcharList:
        Text = Text.replace(Specialchar, ' ')


    return Text

def RemoveNonalphabetWords(Text):
    """
    Definition: User Defined Function (UDF) to clean-up the text.
    Input: Raw text.
    Output: Cleaned-up text.
    """


    # Remove all the non-alphabet words in the given text.
    Text = ' '.join( [Word for Word in Text.split() if Word.isalpha()] )


    return Text

def RemoveStopWords(Text):
    """
    Definition: User Defined Function (UDF) to clean-up the text.
    Input: Raw text.
    Output: Cleaned-up text.
    """


    # Get the list of the NLTK English stop words.
    StopWords = set(stopwords.words('english'))

    # Remove all the NLTK English stop words in the given text.
    Text = ' '.join( [Word for Word in Text.split() if Word not in StopWords] )


    return Text

def KeepWordsofLength(Text):
    """
    Definition: User Defined Function (UDF) to clean-up the text.
    Input: Raw text.
    Output: Cleaned-up text.
    """


    # Remove all the words with length less than a specific value in the given text.
    # (or)
    # Keep all the words with length greater than or equal to a specific value from the given text.
    Text = ' '.join( [Word for Word in Text.split() if len(Word) >= WORD_LENGTH_TO_KEEP] )


    return Text

def RemoveCommonWords(Text):
    """
    Definition: User Defined Function (UDF) to clean-up the text.
    Input: Raw text.
    Output: Cleaned-up text.
    """


    # Remove all the commonly used words between/among the classes in the given text.
    # The idea is, if there are common words between/among the classes,
    # the algorithm gets confused and the accuracy score will go down.
    Text = ' '.join( [Word for Word in Text.split() if Word not in CommonWordSet] )


    return Text

def RemoveNoWeightWords(Text):
    """
    Definition: User Defined Function (UDF) to clean-up the text.
    Input: Raw text.
    Output: Cleaned-up text.
    """


    # Remove all the user specific (or) project specific (or) ..... and so on specific
    # words which carry no weightage in the given text.
    Text = ' '.join( [Word for Word in Text.split() if Word not in NoWeightWordList] )


    return Text

def GetWhitespaceFreeText(Text):
    """
    Definition: User Defined Function (UDF) to clean-up the text.
    Input: Raw text.
    Output: Cleaned-up text.
    """


    # Replace all the white space characters with a space character in the given text.
    Pattern = re.compile(r'\s+', flags=re.I)
    Text = re.sub(Pattern, ' ', Text)

    # Substitute multiple spaces with single space.
    Text = re.sub(r'\s+', ' ', Text, flags=re.I)


    return Text

# def RemoveDuplicateWords(Text):
#     """
#     Definition: User Defined Function (UDF) to clean-up the text.
#     Input: Raw text.
#     Output: Cleaned-up text.
#     """


#     # Note: For projects which require word frequency, please do not use this function.
#     # Note: To remove duplicate elements in a list, we can use the Python's set concept.
#     #       But, the set concept will not preserve the word order, which is important in this case.

#     # Remove the duplicate words in the given text.
#     CheckList = list()
#     TempList = Text.split(' ')
#     [CheckList.append(Word) for Word in TempList if Word not in CheckList]
#     Text = ' '.join(CheckList)


#     return Text

# def GetEmailidFreeText(Text):
#     """
#     Definition: User Defined Function (UDF) to clean-up the text.
#     Input: Raw text.
#     Output: Cleaned-up text.
#     """


#     # Remove all the Email IDs in the given text.
#     Pattern = re.compile(r'[a-zA-Z0-9.-]+@[a-zA-Z-]+\.(com|edu|net)', flags=re.I)
#     Text = re.sub(Pattern, ' ', Text)


#     return Text

# def GetUnderscoreFreeText(Text):
#     """
#     Definition: User Defined Function (UDF) to clean-up the text.
#     Input: Raw text.
#     Output: Cleaned-up text.
#     """


#     # Remove all the words connected by Underscore character (Ex. "hello_how_are_you") in the given text.
#     TempList = Text.split(' ')
#     Text = ' '.join( [Word for Word in TempList if '_' not in Word] )


#     return Text

# def GetPunctuationFreeText(Text):
#     """
#     Definition: User Defined Function (UDF) to clean-up the text.
#     Input: Raw text.
#     Output: Cleaned-up text.
#     """


#     # Remove all the punctuation marks in the given text.
#     Pattern = re.compile("""!"#$%&'()*+,-./:;<=>?@[\]^_`{|}~""", flags=re.I)
#     Text = re.sub('[%s]' % re.escape(Pattern), ' ', Text)


#     return Text

# def GetDigitFreeText(Text):
#     """
#     Definition: User Defined Function (UDF) to clean-up the text.
#     Input: Raw text.
#     Output: Cleaned-up text.
#     """


#     # Remove all the digits in the given text.
#     Pattern = re.compile(r'[0-9]+', flags=re.I)
#     Text = re.sub(Pattern, ' ', Text)


#     return Text

def CleanupText(Text, *FunctionNames):
    """
    Definition: User Defined Function (UDF) to clean-up the text.
    Input: Raw text.
    Output: Cleaned-up text.

    Note(s):
      * Using variable-length parameters concept.
      * Using function as a parameter.
    """


    if len(FunctionNames):
        for FunctionName in FunctionNames:
            # Call specific function.
            Text = FunctionName(Text)


    return Text

def PredictText(Model, Text):
    """
    User Defined Function (UDF) to predict the Label, Class Probability (CP) from the given text.
    Input: Model, Cleaned-up text.
    Output: Predicted Label, Class Probability (CP).
    """


    # User Defined Function (UDF) call to get the cleaned-up text.
    # Note(s):
    #   * Keep the 'GetWhitespaceFreeText' as the last function.
    Text = CleanupText(Text, GetLowerCaseText, GetNonasciiFreeText, GetSpecialcharFreeText, \
                       RemoveNonalphabetWords, RemoveStopWords, KeepWordsofLength, \
                       RemoveCommonWords, RemoveNoWeightWords, GetWhitespaceFreeText)

    # Get the TF-IDF features of the cleaned-up text.
    TfidfTestVectors  = TfIdfObject.transform([Text])

    # Class label.
    Prediction = Model.predict(TfidfTestVectors)[0]

    # Class Probability.
    Cp = Model.predict_proba(TfidfTestVectors)[0]


    return Prediction, Cp

"""<a href="#Contents" style="float:right">[Contents]</a>

<a id=Step_02></a>

## <font color=Green>Step-02: Managing the Data.</font>

<a id=Step_02_Py></a>

### <font color=Red>Python Libraries.</font>
"""

# Basic imports.
import re
import time

# MS-Excel related imports.
import openpyxl
from openpyxl import load_workbook

# NLTK library imports.
import nltk
nltk.download('stopwords')
from nltk.corpus import stopwords
# nltk.download('wordnet')
# nltk.download('punkt')
# from nltk.tokenize import WordPunctTokenizer
# from nltk.stem import WordNetLemmatizer
# from nltk import sent_tokenize
# from nltk import word_tokenize
# from string import punctuation

"""<a id=Step_02_Co></a>

### <font color=Red>Constants.</font>
"""

# Path and file(s).
ROOT_PATH = r"C:\Users\kalya\Desktop\RVHackathon\2024-03-02 ResumeMatch"
INPUT_DATA_EXCEL_FILE_PATH = r"C:\Users\kalya\Desktop\RVHackathon\2024-03-02 ResumeMatch\01_Input\Data"
INPUT_DATA_EXCEL_FILE_NAME = r"ResumeDataSet_TrainTest.xlsx"
OUTPUT_DATA_EXCEL_FILE_PATH = r"C:\Users\kalya\Desktop\RVHackathon\2024-03-02 ResumeMatch\02_Process"
OUTPUT_DATA_EXCEL_FILE_NAME = r"ResumeDataSet_Processed.xlsx"

# Data file related.
WORKSHEET_NAME = r"ResumeDataSet"

# Column name for the cleaned-up text.
CLEAN_TEXT_COL_NAME = "CleanDescription"

# Keep the words having length greater than or equal to this value.
WORD_LENGTH_TO_KEEP = 3

"""<a id=Step_02_Va></a>

### <font color=Red>Variables.</font>
"""

# All the special characters in the order of the ASCII chart.
# Note(s):
#   * Excluded the character '+', because we need the word 'C++'.
SpecialcharList = ['!', '"', '#', '$', '%', '&', "'", '(', ')', '*', ',', '-', '.', '/', ':', ';', '<', '=', '>', '?', '@', '[', '\\', ']', '^', '_', '`', '{', '|', '}', '~' ]

# # Verification.
# print(len(SpecialcharList))

"""<a id=Step_02_Ma></a>

### <font color=Red>Main Code.</font>
"""

# Load the data file i.e. MS-Excel workbook.
TmpPath = INPUT_DATA_EXCEL_FILE_PATH + r'\\' + INPUT_DATA_EXCEL_FILE_NAME
Workbook = load_workbook(filename = TmpPath)
time.sleep(2)

# Select the 'Active' worksheet.
Worksheet = Workbook.active

# Get the number of rows and number of columns of the worksheet.
MinRow = Worksheet.min_row
MinCol = Worksheet.min_column
MaxRow = Worksheet.max_row
MaxCol = Worksheet.max_column

# Verification.
print("Min Row: {:03d}, Min Col: {:03d}".format(MinRow, MinCol))
print("Max Row: {:03d}, Max Col: {:03d}".format(MaxRow, MaxCol))

# Create a Column/Field for the cleaned-up text.
Worksheet.cell(row = MinRow, column = MaxCol + 1).value = CLEAN_TEXT_COL_NAME

# Iterate through worksheet's rows and columns by leaving the header row.
# Get the resume text, clean it up and write into a new column of the same row.
for Row in range(MinRow + 1, MaxRow + 1):
    # Get the content of the cell i.e. resume text.
    CellContent = Worksheet.cell(row = Row, column = MaxCol).value

    # User Defined Function (UDF) call to get the cleaned-up text.
    # Note(s):
    #   * Keep the 'GetWhitespaceFreeText' as the last function.
    Text = CleanupText(CellContent, GetLowerCaseText, GetNonasciiFreeText, GetSpecialcharFreeText, \
                       RemoveNonalphabetWords, RemoveStopWords, KeepWordsofLength, \
                       GetWhitespaceFreeText)

    # Fill the rows of the Column/Field created for the cleaned-up text.
    Worksheet.cell(row = Row, column = MaxCol + 1).value = Text

#     print(Text)
#     print("==========\n")
#     break

# Save the data file i.e. MS-Excel workbook.
TmpPath = OUTPUT_DATA_EXCEL_FILE_PATH + r'\\' + OUTPUT_DATA_EXCEL_FILE_NAME
Workbook.save(filename = TmpPath)
time.sleep(2)

# Close the data file i.e. MS-Excel workbook.
Workbook.close()
time.sleep(2)

"""<a href="#Contents" style="float:right">[Contents]</a>

<a id=Step_03></a>

## <font color=Green>Step-03: Processing the Data.</font>

<a id=Step_03_Py></a>

### <font color=Red>Python Libraries.</font>
"""

"""
Duplicate.
To sync with split file model i.e. separate files for Data, Model, WebApp, GuiApp.
"""

# Basic imports.
import re
import time

"""
Duplicate.
To sync with split file model i.e. separate files for Data, Model, WebApp, GuiApp.
"""

# NLTK library imports.
import nltk
nltk.download('stopwords')
from nltk.corpus import stopwords
# nltk.download('wordnet')
# nltk.download('punkt')
# from nltk.tokenize import WordPunctTokenizer
# from nltk.stem import WordNetLemmatizer
# from nltk import sent_tokenize
# from nltk import word_tokenize
# from string import punctuation

# Boiler plate imports.
import numpy as np
import pandas as pd

# Visualization related imports.
import matplotlib.pyplot as plt
import seaborn as sns

# Word cloud related imports.
from wordcloud import WordCloud

"""<a id=Step_03_Co></a>

### <font color=Red>Constants.</font>
"""

"""
Duplicate.
To sync with split file model i.e. separate files for Data, Model, WebApp, GuiApp.
"""

# Path and file(s).
ROOT_PATH = r"C:\Users\kalya\Desktop\RVHackathon\2024-03-02 ResumeMatch"
OUTPUT_DATA_EXCEL_FILE_PATH = r"C:\Users\kalya\Desktop\RVHackathon\2024-03-02 ResumeMatch\02_Process"
OUTPUT_DATA_EXCEL_FILE_NAME = r"ResumeDataSet_Processed.xlsx"

"""
Duplicate.
To sync with split file model i.e. separate files for Data, Model, WebApp, GuiApp.
"""

# Data file related.
WORKSHEET_NAME = r"ResumeDataSet"

# Column name for the cleaned-up text.
CLEAN_TEXT_COL_NAME = "CleanDescription"

"""
Duplicate.
To sync with split file model i.e. separate files for Data, Model, WebApp, GuiApp.
"""

# Keep the words having length greater than or equal to this value.
WORD_LENGTH_TO_KEEP = 3

# Train-Test split.
# General split ratios are: 80%:20% (or) 75%:25% (or) 70%:30%.
# i.e. 0.8:0.2 (or) 0.75:0.25 (or) 0.7:0.3.

DATA_TRAIN_PERCENTAGE = 0.8
DATA_TEST_PERCENTAGE = 1 - DATA_TRAIN_PERCENTAGE

# Value set to 'random_state' variable.
RANDOM_STATE = 200

"""<a id=Step_03_Va></a>

### <font color=Red>Variables.</font>
"""

"""
Duplicate.
To sync with split file model i.e. separate files for Data, Model, WebApp, GuiApp.
"""

# All the special characters in the order of the ASCII chart.
# Note(s):
#   * Excluded the character '+', because we need the word 'C++'.
SpecialcharList = ['!', '"', '#', '$', '%', '&', "'", '(', ')', '*', ',', '-', '.', '/', ':', ';', '<', '=', '>', '?', '@', '[', '\\', ']', '^', '_', '`', '{', '|', '}', '~' ]

# # Verification.
# print(len(SpecialcharList))

# Python set to store common words across the classes.
CommonWordSet = set()

# Python list to store words which doesn't carry any weithtage.
# The developer/programmer has to fill this list.
# Used in the User Defined Function (UDF) 'RemoveNoWeightWords'.
NoWeightWordList = [
                    'college', 'completed', 'computer', 'cricket', 'crecket',
                    'disctrict', 'engineering', 'experience', 'involved', 'issue',
                    'issues', 'june', 'learning', 'less', 'like',
                    'ltd', 'maharashtra', 'mumbai', 'ofice', 'process',
                    'project', 'pune', 'pvt', 'requirements', 'responsibility',
                    'responsibilities', 'role', 'roles', 'software', 'system',
                    'tamil', 'technology', 'used', 'user', 'users',
                    'using', 'work', 'worked', 'year'
                   ]
# Sort the list in ascending order.
NoWeightWordList.sort(reverse = False)

# Global variable to be used when testing with test data.
TestDataRowsPerLabel = 0

"""<a id=Step_03_Ma></a>

### <font color=Red>Main Code.</font>
"""

# Load the data file(s).
DataFile = OUTPUT_DATA_EXCEL_FILE_PATH + r'\\' + OUTPUT_DATA_EXCEL_FILE_NAME
PdDf = pd.read_excel(DataFile, sheet_name = WORKSHEET_NAME, header = 0)

# Verification.
PdDf.head(2)

# Verification.
PdDf.tail(2)

# Verification.
PdDf.shape

# Check for 'NaN' under a specific column of the Pandas data frame.
if PdDf['ClassLabel'].isnull().values.any():
    print("Before deleting 'NaN' rows of column 'ClassLabel' in data frame:")
    # Count for rows that contain 'NaN' in a specific column of the Pandas data frame.
    print("\tCount of 'NaN' rows: {:05d}".format(PdDf['ClassLabel'].isnull().values.sum()))
    print("\tShape of data frame: {}".format(PdDf.shape))

    # Drop all the rows where the specified column i.e. 'ClassLabel' has a missing value i.e. 'NaN'.
    PdDf.dropna(subset=['ClassLabel'], inplace=True)

    # Reset the index of the Pandas data frame.
    PdDf = PdDf.reset_index(drop=True)

    print("After  deleting 'NaN' rows of column 'ClassLabel' in data frame:")
    # Count for rows that contain 'NaN' in a specific column of the Pandas data frame.
    print("\tCount of 'NaN' rows: {:05d}".format(PdDf['ClassLabel'].isnull().values.sum()))
    print("\tShape of data frame: {}".format(PdDf.shape))

# Check for 'NaN' under a specific column of the Pandas data frame.
if PdDf['CleanDescription'].isnull().values.any():
    print("Before deleting 'NaN' rows of column 'CleanDescription' in data frame:")
    # Count for rows that contain 'NaN' in a specific column of the Pandas data frame.
    print("\tCount of 'NaN' rows: {:05d}".format(PdDf['CleanDescription'].isnull().values.sum()))
    print("\tShape of data frame: {}".format(PdDf.shape))

    # Drop all the rows where the specified column i.e. 'ClassLabel' has a missing value i.e. 'NaN'.
    PdDf.dropna(subset=['CleanDescription'], inplace=True)

    # Reset the index of the Pandas data frame.
    PdDf = PdDf.reset_index(drop=True)

    print("After  deleting 'NaN' rows of column 'CleanDescription' in data frame:")
    # Count for rows that contain 'NaN' in a specific column of the Pandas data frame.
    print("\tCount of 'NaN' rows: {:05d}".format(PdDf['CleanDescription'].isnull().values.sum()))
    print("\tShape of data frame: {}".format(PdDf.shape))

# Verification.
PdDf.head(2)

# Verification.
PdDf.tail(2)

# Verification.
PdDf.shape

# Set and make sure the 'ClassLabel' column data type should be integer.
PdDf['ClassLabel'] = PdDf['ClassLabel'].astype(int)

# Verification.
PdDf.dtypes

# Verification.
PdDf.head(2)

# Verification.
PdDf.tail(2)

# Verification.
PdDf.shape

# Sort the data frame in ascending order based on the value of the 'ClassLabel' column.
# This is to get the labels and the corresponding number of rows into a Python list.
PdDf = PdDf.sort_values(by = 'ClassLabel')

# Reset the index of the Pandas data frame.
PdDf = PdDf.reset_index(drop=True)

# Verification.
PdDf.head(2)

# Verification.
PdDf.tail(2)

# Verification.
PdDf.shape

# Get the unique values of 'ClassLabel' column as a Python list.
ClassLabelList = list(PdDf.ClassLabel.unique())

############################################################
# # ONLY to test with 2 class labels. Temporary purpose.
# print(len(ClassLabelList))

# if len(ClassLabelList) == 3:
#     ClassLabelList.pop()
############################################################

print("Number of Labels: {:}".format(len(ClassLabelList)))
print()

for Idx in range(len(ClassLabelList)):
    print("Index: {:},  Label: {:}".format(Idx, ClassLabelList[Idx]))

# Get the unique values of class names i.e. 'Position' column as a Python list.
ClassNameList = list(PdDf.Position.unique())

print("Number of Names: {:}".format(len(ClassNameList)))
print()

for Idx in range(len(ClassNameList)):
    print("Index: {:},  Label: {:}".format(Idx, ClassNameList[Idx]))

"""##### Note(s):
  * In the next few steps, we are going to group all the rows of a specific 'ClassLabel' in to one Pandas data frame.  So we get 'n' number of data frames where 'n' is equal to the number of classes. For this task, we are using Python's list data type.
  * We are doing this grouping because we are going to devide data into two sub-groups i.e. train sub-group and test sub-group.
  * At the end, the train sub-group will get x% of rows of data consisting of all the labels and test sub-group will get (100-X)% of rows of data consisting of all the labels.
  * This excersize is to make sure that the train sub-group will get all the labels of data rows with a specific volume and test sub-group will get all the labels of data rows with another specific volume.
"""

# Create a 1-Dimension Python list.
# This variable will be a Python list of Pandas data frames i.e.
# each element of this list itself is a Pandas data frame,
# and one data frame contains all the rows of a specific 'ClassLabel'.

# Create a 1-D Python list and initialize all the elements/cells with '0'.
PdDf1DList = [0] * len(ClassLabelList)

# Iterate through the cells of the 1-D Python list.
for Idx in range(len(PdDf1DList)):
    # Filter the Pandas main data frame based on the 'ClassLabel'
    # and send all the matching rows as an individual data frame
    # into one cell of the 1-D Python list.
    PdDf1DList[Idx] = PdDf[PdDf['ClassLabel'] == ClassLabelList[Idx]]


# Verify ONLY in a separate loop.
# This is to make sure, no cell is over-written.
for Idx in range(len(PdDf1DList)):
    print("Label {:2} has {:2} rows of data.".format(Idx, len(PdDf1DList[Idx])))

# Get the info regarding which cell of the 1-D Python list has the minimum number of rows.
MinRows = len(min(PdDf1DList, key=len))
print("Actual minimum number of rows {:}.".format(MinRows))

# In case, if this minimum number is an odd number then make it even.
# This is to make the process simple when deviding data between
# (1) Training data and (2) Testing data.
if MinRows % 2 == 1:
    MinRows -= 1
print("Final  minimum number of rows {:}.".format(MinRows))
print()

# Note(s):
#   * Important - The following is to avoid over limit or under limit of training data,
#     by making the number of rows equal between/among different classes.

# Make sure that all the cells of the 1-D Python list has the same number of rows,
# which is equal to the minimum of all cells in the list i.e. 'MinRows'
# Iterate through the cells of the 1-D Python list.
for Idx in range(len(PdDf1DList)):
    PdDf1DList[Idx] = PdDf1DList[Idx].iloc[:MinRows]


# Verify ONLY in a separate loop.
# This is to make sure, no cell is over-written.
for Idx in range(len(PdDf1DList)):
    print("Label {:2} has {:2} rows of data.".format(Idx, len(PdDf1DList[Idx])))

# Create a 2-Dimension Python list.
#   * The number of rows is equal to the number of unique values of 'ClassLabel'.
#   * The number of columns is equal to 2 (because of 2-D list).
#       * The first column/dimension is to store the Pandas data frame
#         with x% of rows to be used for model training.
#       * The second column/dimension is to store the Pandas data frame
#         with (100 - x)% of rows to be used for model testing.

# Number of columns of the 2-D Python list.
Dimensions = 2

# Create a 2-D Python list and initialize all the elements/cells with '0'.
# PdDf2DList = [[0] * 2] * len(ClassLabelList)
# The above statement will not work because,
# "[0] * 2" is just a reference to a list of '2' zeros but not a list.
# When we write PdDf2DList[2][0], PdDf2DList[1][0], PdDf2DList[0][0], all will have the same value.
PdDf2DList = [[0] * Dimensions for Idx in range(len(ClassLabelList))]
print("Number of rows in the 2-D Python list: {}".format(len(PdDf2DList)))
print("Number of columns in each row of list: {}".format(len(PdDf2DList[0])))
print()

# Iterate through the rows of the 2-D Python list.
for Idx in range(len(PdDf2DList)):
    # x% of rows to be used for model training.
    PdDf2DList[Idx][0] = PdDf1DList[Idx].sample(frac=DATA_TRAIN_PERCENTAGE, random_state=RANDOM_STATE)
    # (100 - x)% of rows to be used for model testing.
    PdDf2DList[Idx][1] = PdDf1DList[Idx].sample(frac=DATA_TEST_PERCENTAGE, random_state=RANDOM_STATE)


# Verify ONLY in a separate loop.
# This is to make sure, no cell is over-written.
for Idx in range(len(PdDf2DList)):
    print("Label {:2}, Train data rows: {:2}, Test data rows: {:2}, Total rows: {:2}." \
          .format(Idx, len(PdDf2DList[Idx][0]), len(PdDf2DList[Idx][1]), \
                  len(PdDf2DList[Idx][0]) + len(PdDf2DList[Idx][1])))


# Global variable to be used when testing with test data.
TestdataRowsPerLabel = len(PdDf2DList[Idx][1])

# Verification.
print()
print("Testing data rows per label: {:}".format(TestdataRowsPerLabel))

# From the 2-D Python list, get the columns of all the rows.
ColumnList = list(zip(*PdDf2DList))

# Pick the '0'th column, which contains x% of rows to be used for model training.
Column0List = list(ColumnList[0])

# Pick the '1'st column, which contains (100 - x)% of rows to be used for model testing.
Column1List = list(ColumnList[1])

# Verify ONLY in a separate loop.
# This is to make sure, no cell is over-written.
for Idx in range(len(Column0List)):
    print("Label {:2}, Train data rows: {:2}.".format(Idx, len(Column0List[Idx])))

print()

# Verify ONLY in a separate loop.
# This is to make sure, no cell is over-written.
for Idx in range(len(Column0List)):
    print("Label {:2}, Test  data rows: {:2}.".format(Idx, len(Column1List[Idx])))

# Note(s):
#   * This 'PdDfLimit' is not required actually, but to just have information.

# Concatanate the data frames of all rows i.e. training data and testing, having individual class labels.
PdDfLimit = pd.concat(Column0List + Column1List)

# Reset the index of the Pandas data frame.
PdDfLimit = PdDfLimit.reset_index(drop=True)


# Verification.
print("Rows in the data frame just for information: {:}".format(len(PdDfLimit)))

# Concatanate the data frames of x% rows i.e. training data, having individual class labels.
PdDfTrain = pd.concat(Column0List)

# Reset the index of the Pandas data frame.
PdDfTrain = PdDfTrain.reset_index(drop=True)


# Verification.
print("Rows in the data frame to be used for training: {:}".format(len(PdDfTrain)))

# Concatanate the data frames of (100 - x)% rows i.e. testing data, having individual class labels.
PdDfTest = pd.concat(Column1List)

# Reset the index of the Pandas data frame.
PdDfTest = PdDfTest.reset_index(drop=True)


# Verification.
print("Rows in the data frame to be used for testing: {:}".format(len(PdDfTest)))

# Note(s):
#   * This is to be used during the testing phase.

# Convert the column of the testing data frame which is to be used as class label to Python list.
PdDfTestClassLabelList = PdDfTest['ClassLabel'].tolist()

# Convert the column of the testing data frame which is to be used as class name to Python list.
PdDfTestClassNameList = PdDfTest['Position'].tolist()

# Convert the column of the testing data frame which is to be used as actual data to Python list.
PdDfTestActualDataList = PdDfTest['CleanDescription'].tolist()


# Verification.
print("Total number of rows in test data: {:}.".format(len(PdDfTestClassLabelList)))
print()
print("First row's class label: {:}.".format(PdDfTestClassLabelList[0]))
print("First row's class  name: {:}.".format(PdDfTestClassNameList[0]))
print("First row's actual data: {:}.".format(PdDfTestActualDataList[0]))
print()
print("Last  row's class label: {:}.".format(PdDfTestClassLabelList[-1]))
print("Last  row's class  name: {:}.".format(PdDfTestClassNameList[-1]))
print("Last  row's actual data: {:}.".format(PdDfTestActualDataList[-1]))

"""##### Full Data Frame:"""

# Verification.
PdDf.head(2)

# Verification.
PdDf.tail(2)

# Verification.
PdDf.shape

"""##### Limited Data Frame:"""

# Verification.
PdDfLimit.head(2)

# Verification.
PdDfLimit.tail(2)

# Verification.
PdDfLimit.shape

"""##### Train Data Frame:"""

# Verification.
PdDfTrain.head(2)

# Verification.
PdDfTrain.tail(2)

# Verification.
PdDfTrain.shape

"""##### Test Data Frame:"""

# Verification.
PdDfTest.head(2)

# Verification.
PdDfTest.tail(2)

# Verification.
PdDfTest.shape

"""##### Note(s):
  * From this point on wards,
    * We use train data frame for model training.
    * We use test data frame for model testing.
    * We do not use the full data frame and limit data frame in any case and these are just for information.
"""

# Verification.
PdDfTrain.head(2)

# Verification.
PdDfTrain.tail(2)

# Verification.
PdDfTrain.shape

# Add the column that contains the cleaned-up text to the Pandas train data frame.
PdDfTrain['CleanText'] = PdDfTrain.CleanDescription.apply( \
                            lambda CleanDescription: CleanupText(CleanDescription, \
                                GetLowerCaseText, GetNonasciiFreeText, GetSpecialcharFreeText, \
                                    RemoveNonalphabetWords, RemoveStopWords, KeepWordsofLength, \
                                        GetWhitespaceFreeText))

# Move/shift a specific column to a specific index/position.
TempColumn = PdDfTrain.pop('CleanText')
PdDfTrain.insert((len(PdDfTrain.columns) - 0), 'CleanText', TempColumn)

# Verification.
PdDfTrain.head(2)

# Verification.
PdDfTrain.tail(2)

# Verification.
PdDfTrain.shape

# Remove unused columns from the Pandas train data frame.
TempColumn = PdDfTrain.pop('Group')
TempColumn = PdDfTrain.pop('Row')
TempColumn = PdDfTrain.pop('Resume')
# TempColumn = PdDfTrain.pop('CleanDescription')

# Verification.
PdDfTrain.style

# Verification.
PdDfTrain.head(2)

# Verification.
PdDfTrain.tail(2)

# Verification.
PdDfTrain.shape

# Verification.
PdDfTrain.describe()

# Verification.
PdDfTrain.info(2)

# Verification.
PdDfTrain.dtypes

# Keep a back-up copy of the Pandas train data frame.
PdDfTrainBackup = PdDfTrain.copy()

# Verification.
PdDfTrainBackup.shape

"""<a id=Step_03_Manage></a>

#### <font color=Orange>Manage Common Words Between/Among Classes.</font>

* This part of the code gives a Python set of words that are common across all the classes.
* These common words are going to be stored in 'CommonWordSet'.
* The idea is, if there are common words across the classes, the algorithm gets confused and the accuracy score will go down.
* Implemented a User Defined Function (UDF) 'RemoveCommonWords' which uses the Python set 'CommonWordSet'. Call this function from another User Defined Function (UDF) 'CleanupText', so these common words are removed across all the classes of text rows.
* Note(s):
  * For projects, which are dependent on the word frequency, do not remove the duplicate words.
"""

# Create a 1-Dimension Python list with number of elements equal to the number of class labels.
#   * The '0'th element of this 1-D Python list contains the list of all the text words belongs to class label '0'.
#   * The '1'st element of this 1-D Python list contains the list of all the text words belongs to class label '1'.
#   and so on.

# Create a 1-D Python list and initialize all the elements/cells with ''.
# WordList = [[''] * len(ClassLabelList)] # This will not work.
WordList = [[''] * Idx for Idx in range(len(ClassLabelList))]

print("Before removing duplicates: ")

# Iterate through the cells of the 'ClassLabelList' list.
for ClassLabel in range(len(ClassLabelList)):
    # Get all the rows of a matching label of column 'CleanText' into Pandas data frame.
    PdDfForList = PdDfTrain.loc[PdDfTrain['ClassLabel'] == ClassLabel, ['CleanText']]

    # Iterate through the rows of the 'CleanText' column of the Pandas data frame.
    for Idx in PdDfForList.index:
        # Get the text sentence and split into words.
        Tmplist = PdDfForList['CleanText'][Idx].split(' ')

        # Add all the words belongs to on class label to the corresponding element of the main word list.
        WordList[ClassLabel].extend(Tmplist)

    print("\tNumber of words belongs to class label {:2d} are: {:4d}".format(ClassLabel, len(WordList[ClassLabel])))

# Remove the duplicate words within each class, so that each class has its unique words.

print("After removing duplicates: ")

# Iterate through the cells of the 'WordList' list.
for Idx in range(len(WordList)):
    # Get all the words belongs to one class label from the corresponding element of the main word list.
    # Then remove the duplicate words using Python's set concept.
    # Then store back the corresponding cells.
    WordList[Idx] = list(set(WordList[Idx]))

    # Sort the list in ascending order.
    WordList[Idx].sort(reverse = False)

    print("\tNumber of words belongs to class label {:2d} are: {:4d}".format(Idx, len(WordList[Idx])))

# Initialize the Python set global variable 'CommonWordSet' with the unique words belongs to class lable '0'.
CommonWordSet = set(WordList[0])
# print("List   of unique words of class label {:2d}: {:}".format(0, set(WordList[0])))
print()

# Iterate through the cells of the 'WordList' list.
# In first iteration, there will ba a set intersect operation between
# the '0'th cell of 'WordList' and the '1'st cell of 'WordList', which is NOT an issue.
# for Idx in range(len(WordList)):
for Idx in range(1, len(WordList)):
    TmpVar = set(WordList[Idx - 1])
    TmpVar = TmpVar.intersection(set(WordList[Idx]))
    CommonWordSet = CommonWordSet.intersection(set(WordList[Idx]))
    # print("List   of unique words of class label {:2d}: {:}".format(Idx, set(WordList[Idx])))
    print("Number of unique words of class label {:2d}: {:3d}".format(Idx - 1, len(set(WordList[Idx - 1]))))
    print("Number of unique words of class label {:2d}: {:3d}".format(Idx, len(set(WordList[Idx]))))
    print("#  Unique common words between {:2d} and {:2d}: {:3d}".format(Idx - 1, Idx, len(TmpVar)))
    print("#  Unique common words from    {:2d} to  {:2d}: {:3d}".format(0, Idx, len(CommonWordSet)))
    print()

# Verification.
print("----------")
print("Number of common words across all classes: {:}".format(len(CommonWordSet)))
print("List   of common words across all classes: {:}".format(CommonWordSet))

"""<a href="#Contents" style="float:right">[Contents]</a>

<a id=Step_04></a>

## <font color=Green>Step-04: Visualizing the Data.</font>

<a id=Step_04_Py></a>

### <font color=Red>Python Libraries.</font>
"""

# Visualization related imports.
import matplotlib.pyplot as plt
import seaborn as sns

from matplotlib.gridspec import GridSpec

# Word cloud related imports.
from wordcloud import WordCloud

# Image processing related imports.
from PIL import Image

"""<a id=Step_04_Co></a>

### <font color=Red>Constants.</font>
"""

# Path and file(s).
# Mask image to show the word cloud.
ROOT_PATH = r"C:\Users\kalya\Desktop\RVHackathon\2024-03-02 ResumeMatch"
MASK_IMAGE_PATH = r"01_Input\Support\MagniFier.jpg"

# To show top 'n' words.
CHART_WORDS = 10

"""<a id=Step_04_Va></a>

### <font color=Red>Variables.</font>
"""

# None.

"""<a id=Step_04_Ma></a>

### <font color=Red>Main Code.</font>
"""

plt.figure(figsize=(20, 5))
plt.xticks(rotation=90)
Ax = sns.countplot(x="Position", data=PdDfTrain)

for Patch in Ax.patches:
    Ax.annotate(str(Patch.get_height()), (Patch.get_x() * 1.01, Patch.get_height() * 1.01))

plt.grid()

TargetCounts = PdDfTrain['Position'].value_counts()
TargetLabels = PdDfTrain['Position'].unique()

plt.figure(1, figsize=(22, 22))
TheGrid = GridSpec(2, 2)

cmap = plt.get_cmap('coolwarm')
plt.subplot(TheGrid[0, 1], aspect=1, title="Category Distribution")

source_pie = plt.pie(TargetCounts, labels=TargetLabels, autopct='%1.1f%%', shadow=True)

# Iterate through the cells of the 'ClassLabelList' list.
for Idx in range(len(ClassLabelList)):
    Title = "Top {:} Words of 'ClassLabel' {:} Category i.e. {:s}" \
        .format(CHART_WORDS, ClassLabelList[Idx], ClassNameList[Idx])
    Text = " ".join(PdDfTrain[PdDfTrain.ClassLabel == ClassLabelList[Idx]].CleanText)
    DfCount = pd.DataFrame(Text.split(), columns = ['Words'])
    Top_N = DfCount[DfCount['Words'].isin(list(DfCount.Words.value_counts()[:CHART_WORDS].index[:CHART_WORDS]))]
    plt.figure(figsize=(15, 5))
    sns.barplot(x = Top_N.Words.value_counts().index, y = Top_N.Words.value_counts(), \
                palette = sns.color_palette("viridis")).set_title(Title)

"""<a id=Step_04_Cleaning></a>

#### <font color=Orange>Cleaning-up the Data with the Help of Visualization.</font>

##### Round-01:
"""

# Verification.
PdDfTrain.head(2)

# Verification.
PdDfTrain.tail(2)

# Verification.
PdDfTrain.shape

# Remove the 'CleanText' column. We are going to clean the text further,
# of column 'CleanDescription' and add the cleaned text under new 'CleanText' column again.
TempColumn = PdDfTrain.pop('CleanText')

# Verification.
PdDfTrain.head(2)

# Verification.
PdDfTrain.tail(2)

# Verification.
PdDfTrain.shape

# Add the column that contains the cleaned-up text to the Pandas train data frame.
PdDfTrain['CleanText'] = PdDfTrain.CleanDescription.apply( \
                            lambda CleanDescription: CleanupText(CleanDescription, \
                                GetLowerCaseText, GetNonasciiFreeText, GetSpecialcharFreeText, \
                                    RemoveNonalphabetWords, RemoveStopWords, KeepWordsofLength, \
                                        RemoveCommonWords, GetWhitespaceFreeText))

# Move/shift a specific column to a specific index/position.
TempColumn = PdDfTrain.pop('CleanText')
PdDfTrain.insert((len(PdDfTrain.columns) - 0), 'CleanText', TempColumn)

# Verification.
PdDfTrain.head(2)

# Verification.
PdDfTrain.tail(2)

# Verification.
PdDfTrain.shape

# Verification.
print("Number of words in 0th row of 'CleanDescription' column: {:}".format(len(PdDfTrain['CleanDescription'][0])))
print("Number of words in 0th row of 'CleanText'        column: {:}".format(len(PdDfTrain['CleanText'][0])))
print("The effect of clean-up in terms of reduced text words  : {:}".format(len(PdDfTrain['CleanDescription'][0]) - len(PdDfTrain['CleanText'][0])))

# Verification.
TmpTextList = list()

# Iterate through the rows of the Pandas train data frame.
for Idx, Row in PdDfTrain.iterrows():
    TmpTextList.append(Row['CleanText'])
    print(Row['ClassLabel'])
    print(Row['Position'])
    print(Row['CleanText'])
    print("==========\n")

# Iterate through the cells of the 'ClassLabelList' list.
for Idx in range(len(ClassLabelList)):
    Title = "Top {:} Words of 'ClassLabel' {:} Category i.e. {:s}" \
        .format(CHART_WORDS, ClassLabelList[Idx], ClassNameList[Idx])
    Text = " ".join(PdDfTrain[PdDfTrain.ClassLabel == ClassLabelList[Idx]].CleanText)
    DfCount = pd.DataFrame(Text.split(), columns = ['Words'])
    Top_N = DfCount[DfCount['Words'].isin(list(DfCount.Words.value_counts()[:CHART_WORDS].index[:CHART_WORDS]))]
    plt.figure(figsize=(15, 5))
    sns.barplot(x = Top_N.Words.value_counts().index, y = Top_N.Words.value_counts(), \
                palette = sns.color_palette("viridis")).set_title(Title)

# # Iterate through the cells of the 'ClassLabelList' list.
# for Idx in range(len(ClassLabelList)):
#     # Title = "Top {:} Words of 'ClassLabel' {:} Category i.e. {:s}" \
#     #     .format(CHART_WORDS, ClassLabelList[Idx], ClassNameList[Idx])
#     Text = " ".join(PdDfTrain[PdDfTrain.ClassLabel == ClassLabelList[Idx]].CleanText)
#     Wc = WordCloud(width=800, height=800, background_color='white', min_font_size=10).generate(Text)
#     plt.figure(figsize=(10, 8))
#     plt.axis('off')
#     plt.imshow(Wc)
#     plt.tight_layout(pad=0)
#     plt.show()
#     print()

# Create an array from the image that we want to use as a mask.
TmpPath = ROOT_PATH + r'\\' + MASK_IMAGE_PATH
ImgMask = np.array(Image.open(TmpPath))

# Iterate through the cells of the 'ClassLabelList' list.
for Idx in range(len(ClassLabelList)):
    Title = "Top {:} Words of 'ClassLabel' {:} Category i.e. {:s}" \
            .format(CHART_WORDS, ClassLabelList[Idx], ClassNameList[Idx])
    Text = " ".join(PdDfTrain[PdDfTrain.ClassLabel == ClassLabelList[Idx]].CleanText)

    Wc = WordCloud(
                    scale = 3,
                    max_words = CHART_WORDS,
                    colormap = 'RdYlGn',
                    mask = ImgMask,
                    background_color='white',
                    collocations = True,
                    contour_color = 'black',
                    contour_width = 1,
                  ).generate_from_text(Text)

    plt.figure(figsize=(10, 8))
    plt.imshow(Wc)
    plt.axis('off')
    plt.title(Title)
    # plt.tight_layout(pad=0)
    plt.show()
    print()

"""##### Round-02:"""

# Verification.
PdDfTrain.head(2)

# Verification.
PdDfTrain.tail(2)

# Verification.
PdDfTrain.shape

# Remove the 'CleanText' column. We are going to clean the text further,
# of column 'CleanDescription' and add the cleaned text under new 'CleanText' column again.
TempColumn = PdDfTrain.pop('CleanText')

# Verification.
PdDfTrain.head(2)

# Verification.
PdDfTrain.tail(2)

# Verification.
PdDfTrain.shape

# Add the column that contains the cleaned-up text to the Pandas train data frame.
PdDfTrain['CleanText'] = PdDfTrain.CleanDescription.apply( \
                            lambda CleanDescription: CleanupText(CleanDescription, \
                                GetLowerCaseText, GetNonasciiFreeText, GetSpecialcharFreeText, \
                                    RemoveNonalphabetWords, RemoveStopWords, KeepWordsofLength, \
                                        RemoveCommonWords, RemoveNoWeightWords, GetWhitespaceFreeText))

# Move/shift a specific column to a specific index/position.
TempColumn = PdDfTrain.pop('CleanText')
PdDfTrain.insert((len(PdDfTrain.columns) - 0), 'CleanText', TempColumn)

# Verification.
PdDfTrain.head(2)

# Verification.
PdDfTrain.tail(2)

# Verification.
PdDfTrain.shape

# Verification.
print("Number of words in 0th row of 'CleanDescription' column: {:}".format(len(PdDfTrain['CleanDescription'][0])))
print("Number of words in 0th row of 'CleanText'        column: {:}".format(len(PdDfTrain['CleanText'][0])))
print("The effect of clean-up in terms of reduced text words  : {:}".format(len(PdDfTrain['CleanDescription'][0]) - len(PdDfTrain['CleanText'][0])))

# Verification.
TmpTextList = list()

# Iterate through the rows of the Pandas train data frame.
for Idx, Row in PdDfTrain.iterrows():
    TmpTextList.append(Row['CleanText'])
    print(Row['ClassLabel'])
    print(Row['Position'])
    print(Row['CleanText'])
    print("==========\n")

# Iterate through the cells of the 'ClassLabelList' list.
for Idx in range(len(ClassLabelList)):
    Title = "Top {:} Words of 'ClassLabel' {:} Category i.e. {:s}" \
        .format(CHART_WORDS, ClassLabelList[Idx], ClassNameList[Idx])
    Text = " ".join(PdDfTrain[PdDfTrain.ClassLabel == ClassLabelList[Idx]].CleanText)
    DfCount = pd.DataFrame(Text.split(), columns = ['Words'])
    Top_N = DfCount[DfCount['Words'].isin(list(DfCount.Words.value_counts()[:CHART_WORDS].index[:CHART_WORDS]))]
    plt.figure(figsize=(15, 5))
    sns.barplot(x = Top_N.Words.value_counts().index, y = Top_N.Words.value_counts(), \
                palette = sns.color_palette("viridis")).set_title(Title)

# # Iterate through the cells of the 'ClassLabelList' list.
# for Idx in range(len(ClassLabelList)):
#     # Title = "Top {:} Words of 'ClassLabel' {:} Category i.e. {:s}" \
#     #     .format(CHART_WORDS, ClassLabelList[Idx], ClassNameList[Idx])
#     Text = " ".join(PdDfTrain[PdDfTrain.ClassLabel == ClassLabelList[Idx]].CleanText)
#     Wc = WordCloud(width=800, height=800, background_color='white', min_font_size=10).generate(Text)
#     plt.figure(figsize=(10, 8))
#     plt.axis('off')
#     plt.imshow(Wc)
#     plt.tight_layout(pad=0)
#     plt.show()
#     print()

# Create an array from the image that we want to use as a mask.
TmpPath = ROOT_PATH + r'\\' + MASK_IMAGE_PATH
ImgMask = np.array(Image.open(TmpPath))

# Iterate through the cells of the 'ClassLabelList' list.
for Idx in range(len(ClassLabelList)):
    Title = "Top {:} Words of 'ClassLabel' {:} Category i.e. {:s}" \
            .format(CHART_WORDS, ClassLabelList[Idx], ClassNameList[Idx])
    Text = " ".join(PdDfTrain[PdDfTrain.ClassLabel == ClassLabelList[Idx]].CleanText)

    Wc = WordCloud(
                    scale = 3,
                    max_words = CHART_WORDS,
                    colormap = 'RdYlGn',
                    mask = ImgMask,
                    background_color='white',
                    collocations = True,
                    contour_color = 'black',
                    contour_width = 1,
                  ).generate_from_text(Text)

    plt.figure(figsize=(10, 8))
    plt.imshow(Wc)
    plt.axis('off')
    plt.title(Title)
    # plt.tight_layout(pad=0)
    plt.show()
    print()

# Move/shift a specific column to a specific index/position.
TempColumn = PdDfTrain.pop('ClassLabel')
PdDfTrain.insert((len(PdDfTrain.columns) - 0), 'ClassLabel', TempColumn)

# Verification.
PdDfTrain.head(2)

# Verification.
PdDfTrain.tail(2)

# Verification.
PdDfTrain.shape

"""<a href="#Contents" style="float:right">[Contents]</a>

<a id=Step_05></a>

## <font color=Green>Step-05: Vectorizing the Data.</font>

<a id=Step_05_Py></a>

### <font color=Red>Python Libraries.</font>
"""

# Text Representation.
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.feature_extraction.text import TfidfVectorizer

# To save and load vectorizers and models as pickle binary files.
import pickle

"""<a id=Step_05_Co></a>

### <font color=Red>Constants.</font>
"""

# Path and file(s).
ROOT_PATH = r"C:\Users\kalya\Desktop\RVHackathon\2024-03-02 ResumeMatch"
VECTOR_FILE_PATH = r"03_Output"
COUNT_VECTOR_FILE_NAME = r"CountVector.pickle"
TFIDF_VECTOR_FILE_NAME = r"TfIdf.pickle"

"""<a id=Step_05_Va></a>

### <font color=Red>Variables.</font>
"""

# None.

"""<a id=Step_05_Ma></a>

### <font color=Red>Main Code.</font>

Note(s):
* Here we can use dimensionality reduction techniques if the feature vector size is huge.
* Try t-SNE dimensionality reduction technique.

<a id=Step_05_Word2Vec></a>

#### <font color=Orange>01. Word2Vec Vectorizer.</font>

* Word2Vec requires the downloaded pre-trained file which is huge in size.
* As of now, TF-IDF is the best, go ahead with TF-IDF.

<a id=Step_05_Glove></a>

#### <font color=Orange>02. Glove Vectorizer.</font>

* As of now, TF-IDF is the best, go ahead with TF-IDF.

<a id=Step_05_CV></a>

#### <font color=Orange>03. Count Vectorizer.</font>

Note(s):
* To get binary values (1 for present or 0 for absent) instead of counts of terms/tokens, give binary=True.
* N-Gram range basically lets you decide the length of the sequence of consecutive words in the given text.
  * Suppose the n-gram range = (1, 2), then it will pick the unigram (only single word), bigram (group of 2 consecutive words).
  * Suppose the n-gram range = (1, 3), then it will pick the unigram (only single word), bigram (group of 2 consecutive words) and also the trigram (group of 3 consecutive words).
"""

# Convert raw text into a matrix of Count Vectorizer features.
CountVectObject = CountVectorizer(binary = True, ngram_range = (2, 4))

# Tokenize and build vocabulary.
CountVectObject.fit(PdDfTrain['CleanText'])

# Get feature vector.
CountVectors = CountVectObject.transform(PdDfTrain['CleanText'])

# Verification.
CountVectors.shape

# Save the vectorizer.
TmpPath = ROOT_PATH + r'\\' + VECTOR_FILE_PATH + r'\\' + COUNT_VECTOR_FILE_NAME

with open(TmpPath, 'wb') as PickleFile:
    pickle.dump(CountVectObject, PickleFile)

# Note(s):
#   * This cell is ONLY to verify N-Gram concept.

# Convert raw text into a matrix of Count Vectorizer features.
CountVectObj = CountVectorizer(binary = True, ngram_range = (2, 4))

# Tokenize and build vocabulary.
CountVectObj.fit(PdDfTrain['CleanText'])

# Get feature vector.
CountVectorsTmp = CountVectObj.transform(PdDfTrain['CleanText'])

# Verification.
CountVectorsTmp.shape
print()

Vocabulary = CountVectObj.fit(PdDfTrain['CleanText']).vocabulary_
print(Vocabulary)

print(CountVectorsTmp)
print()

"""<a id=Step_05_TV></a>

#### <font color=Orange>04. TF-IDF Vectorizer.</font>

Note(s):
* To get binary values (1 for present or 0 for absent) instead of counts of terms/tokens, give binary=True.
* N-Gram range basically lets you decide the length of the sequence of consecutive words in the given text.
  * Suppose the n-gram range = (1, 2), then it will pick the unigram (only single word), bigram (group of 2 consecutive words).
  * Suppose the n-gram range = (1, 3), then it will pick the unigram (only single word), bigram (group of 2 consecutive words) and also the trigram (group of 3 consecutive words).
"""

# Convert raw text into a matrix of TF-IDF features.
TfIdfObject = TfidfVectorizer()

# Tokenize and build vocabulary.
TfIdfObject.fit(PdDfTrain['CleanText'])

# Get feature vector.
TfidfVectors = TfIdfObject.transform(PdDfTrain['CleanText'])

# Verification.
TfidfVectors.shape

# Save the vectorizer.
TmpPath = ROOT_PATH + r'\\' + VECTOR_FILE_PATH + r'\\' + TFIDF_VECTOR_FILE_NAME

with open(TmpPath, 'wb') as PickleFile:
    pickle.dump(TfIdfObject, PickleFile)

# Note(s):
#   * This cell is ONLY to verify N-Gram concept.

# Convert raw text into a matrix of TF-IDF features.
TfIdfObj = TfidfVectorizer(binary = True, ngram_range = (2, 4))

# Tokenize and build vocabulary.
TfIdfObj.fit(PdDfTrain['CleanText'])

# Get feature vector.
TfidfVectorsTmp = TfIdfObj.transform(PdDfTrain['CleanText'])

# Verification.
TfidfVectorsTmp.shape
print()

Vocabulary = TfIdfObj.fit(PdDfTrain['CleanText']).vocabulary_
print(Vocabulary)

print(TfidfVectorsTmp)
print()

"""<a href="#Contents" style="float:right">[Contents]</a>

<a id=Step_06></a>

## <font color=Green>Step-06: Feature Selection.</font>

<a id=Step_06_Py></a>

### <font color=Red>Python Libraries.</font>
"""

# Train and test data split related imports.
from sklearn.model_selection import train_test_split

"""<a id=Step_06_Co></a>

### <font color=Red>Constants.</font>
"""

# None.

"""<a id=Step_06_Va></a>

### <font color=Red>Variables.</font>
"""

# None.

"""<a id=Step_06_Ma></a>

### <font color=Red>Main Code.</font>
"""

# Verification.
PdDfTrain.head(2)

# Verification.
PdDfTrain.tail(2)

# Verification.
PdDfTrain.shape

# Get the 'X' i.e. Features and 'y' i.e. Labels.
X = TfidfVectors.copy()
y = PdDfTrain.iloc[:, -1].copy()

# Verification.
X.shape

# Verification.
y.shape

# Train-Test split. General split ratios are: 80% - 20% (or) 75% - 25% (or) 70% - 30%.
X_train, X_test, y_train, y_test = train_test_split(X, y, stratify = y, test_size = DATA_TEST_PERCENTAGE)

# Verification.
X_train.shape

# Verification.
X_test.shape

# Verification.
y_train.shape

# Verification.
y_test.shape

"""<a href="#Contents" style="float:right">[Contents]</a>

<a id=Step_07></a>

## <font color=Green>Step-07: AIML Model.</font>

<a id=Step_07_Py></a>

### <font color=Red>Python Libraries.</font>
"""

# Finding the optimal hyper parameters.
from sklearn.model_selection import RandomizedSearchCV

# Models to be trained.
import xgboost

from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import MultinomialNB
from sklearn.linear_model import SGDClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.ensemble import VotingClassifier
from sklearn.ensemble import StackingClassifier

# Metrics and validation.
from sklearn.metrics import accuracy_score
from sklearn.metrics import cohen_kappa_score
from sklearn.metrics import confusion_matrix
from sklearn.metrics import classification_report

# Model cross validation.
from sklearn.model_selection import KFold
from sklearn.model_selection import cross_val_score

# Computation.
from numpy import mean
from numpy import std

# To save and load vectorizers and models as pickle binary files.
import pickle

"""<a id=Step_07_Co></a>

### <font color=Red>Constants.</font>
"""

# Path and file(s).
ROOT_PATH = r"C:\Users\kalya\Desktop\RVHackathon\2024-03-02 ResumeMatch"
MODEL_FILE_PATH = r"03_Output"
MODEL_LRG_FILE_NAME = r"LogisticRegression.pickle"
MODEL_MNB_FILE_NAME = r"MultinomialNaiveBayes.pickle"
MODEL_SGD_FILE_NAME = r"SgdClassifierWithHingeLossSvm.pickle"
MODEL_DTC_FILE_NAME = r"DecisionTree.pickle"
MODEL_KNN_FILE_NAME = r"KnearestNeighbors.pickle"
MODEL_SVM_FILE_NAME = r"Svm.pickle"
MODEL_SVC_FILE_NAME = r"SoftVoting.pickle"
MODEL_STK_FILE_NAME = r"Stacking.pickle"

"""<a id=Step_07_Va></a>

### <font color=Red>Variables.</font>
"""

# None.

"""<a id=Step_07_Ma></a>

### <font color=Red>Main Code.</font>

<a id=Step_07_ModelLrg></a>

#### <font color=Orange>01. [Base Model] Logistic Regression with RandomizedSearchCV.</font>
"""

C = np.arange(0, 1, 0.001)
max_iter = range(100, 500)
warm_start = [True, False]
solver = ['lbfgs', 'newton-cg', 'liblinear']
penalty = ['l2', 'l1']

params = {
          'C' : C,
          'max_iter' : max_iter,
          'warm_start' : warm_start,
          'solver' : solver,
          'penalty' : penalty
         }

random_search = RandomizedSearchCV(
                                    estimator = LogisticRegression(random_state = 1),
                                    param_distributions = params,
                                    n_iter = 100,
                                    cv = 3,
                                    n_jobs = -1,
                                    random_state = 1,
                                    verbose = 1
                                  ).fit(X_train, y_train)

# Get the 'cv_results_' into a Pandas data frame to display in a clean look.
# print(random_search.cv_results_)
MyDf = pd.DataFrame(random_search.cv_results_)

# Get the most important 'cv_results_' of the Pandas data frame for display.
MyDf[['param_C', 'params', 'mean_test_score']]

# Verification of available functions/methods.
# dir(random_search)
print("Best score    : {:.2f}".format(random_search.best_score_))
print("Best params   : {:}".format(random_search.best_params_))
print("Best estimator: {:}".format(random_search.best_estimator_))

# Create the object for the model/classifier.
ModelLrg = random_search.best_estimator_

# # Note(s):
# #   * This part is already done using 'RandomizedSearchCV'.

# # Training/fitting the model/classifier (Using training data).
# ModelLrg.fit(X_train, y_train)

# Estimate the accuracy (or) Calculate the accuracy (or) Calculate the score of the model/classifier.
ScoreLrg = ModelLrg.score(X_test, y_test)

# Verification.
print("Score of the Model/Classifier: {:0.05f}".format(ScoreLrg))

# Predict/Test using the trained model/classifier.
y_pred = ModelLrg.predict(X_test)

# Verification.
# print("Actual    labels: {:}".format(y_test.tolist()))
# print("Predicted labels: {:}".format(y_pred))
# print((pd.DataFrame({'ActualLabels': y_test.tolist(), 'PredictedLabels': y_pred})).to_string(index=False))
(pd.DataFrame({'ActualLabels': y_test.tolist(), 'PredictedLabels': y_pred})).style.hide()

# Method-01: Evaluate the accuracy of the model/classifier.
AsLrg = accuracy_score(y_test, y_pred)

# Verification.
print("Accuracy Score: {:0.05f}".format(AsLrg))

# Method-02: Evaluate the accuracy of the model/classifier.
KsLrg = cohen_kappa_score(y_test, y_pred)

# Verification.
print("Kohen Kappa Score: {:0.05f}".format(KsLrg))

# Confusion matrix of the model/classifier.
CmLrg = confusion_matrix(y_test, y_pred)

# Verification.
print("Confusion matrix: \n")
print(CmLrg)

# Classification report of the model/classifier.
CrLrg = classification_report(y_test, y_pred)

# Verification.
print("Classification report: \n")
print(CrLrg)

# Dataframe with Accuracy score and Cohen Kappa score for later comparison.
DfLrg = pd.DataFrame([AsLrg, KsLrg], \
                     columns = ["01. [Base Model] Logistic Regression"])

# Save the model/classifier.
TmpPath = ROOT_PATH + r'\\' + MODEL_FILE_PATH + r'\\' + MODEL_LRG_FILE_NAME

with open(TmpPath, 'wb') as PickleFile:
    pickle.dump(ModelLrg, PickleFile)

# Load the model/classifier to ensure it is working fine.
TmpPath = ROOT_PATH + r'\\' + MODEL_FILE_PATH + r'\\' + MODEL_LRG_FILE_NAME

with open(TmpPath, 'rb') as PickleFile:
    ModelLrgTmp = pickle.load(PickleFile)

# Predict/Test using the loaded model/classifier.
t_pred = ModelLrgTmp.predict(X_test)

# Verification.
print("Confusion matrix: \n")
print(confusion_matrix(y_test, t_pred))

"""<a id=Step_07_ModelMnb></a>

#### <font color=Orange>02. [Base Model] Multinomial Naive Bayes with RandomizedSearchCV.</font>
"""

alpha = np.arange(0, 1, 0.001)
fit_prior = [True, False]

params =  {
            'alpha' : alpha,
            'fit_prior' : fit_prior
          }

random_search = RandomizedSearchCV(
                                    estimator = MultinomialNB(),
                                    param_distributions = params,
                                    n_iter = 100,
                                    cv = 3,
                                    n_jobs = -1,
                                    random_state = 1,
                                    verbose = 1
                                  ).fit(X_train, y_train)

# Get the 'cv_results_' into a Pandas data frame to display in a clean look.
# print(random_search.cv_results_)
MyDf = pd.DataFrame(random_search.cv_results_)

# Get the most important 'cv_results_' of the Pandas data frame for display.
MyDf[['param_alpha', 'params', 'mean_test_score']]

# Verification of available functions/methods.
# dir(random_search)
print("Best score    : {:.2f}".format(random_search.best_score_))
print("Best params   : {:}".format(random_search.best_params_))
print("Best estimator: {:}".format(random_search.best_estimator_))

# Create the object for the model/classifier.
ModelMnb = random_search.best_estimator_

# # Note(s):
# #   * This part is already done using 'RandomizedSearchCV'.

# # Training/fitting the model/classifier (Using training data).
# ModelMnb.fit(X_train, y_train)

# Estimate the accuracy (or) Calculate the accuracy (or) Calculate the score of the model/classifier.
ScoreMnb = ModelMnb.score(X_test, y_test)

# Verification.
print("Score of the Model/Classifier: {:0.05f}".format(ScoreMnb))

# Predict/Test using the trained model/classifier.
y_pred = ModelMnb.predict(X_test)

# Verification.
# print("Actual    labels: {:}".format(y_test.tolist()))
# print("Predicted labels: {:}".format(y_pred))
# print((pd.DataFrame({'ActualLabels': y_test.tolist(), 'PredictedLabels': y_pred})).to_string(index=False))
(pd.DataFrame({'ActualLabels': y_test.tolist(), 'PredictedLabels': y_pred})).style.hide()

# Method-01: Evaluate the accuracy of the model/classifier.
AsMnb = accuracy_score(y_test, y_pred)

# Verification.
print("Accuracy Score: {:0.05f}".format(AsMnb))

# Method-02: Evaluate the accuracy of the model/classifier.
KsMnb = cohen_kappa_score(y_test, y_pred)

# Verification.
print("Kohen Kappa Score: {:0.05f}".format(KsMnb))

# Confusion matrix of the model/classifier.
CmMnb = confusion_matrix(y_test, y_pred)

# Verification.
print("Confusion matrix: \n")
print(CmMnb)

# Classification report of the model/classifier.
CrMnb = classification_report(y_test, y_pred)

# Verification.
print("Classification report: \n")
print(CrMnb)

# Dataframe with Accuracy score and Cohen Kappa score for later comparison.
DfMnb = pd.DataFrame([AsMnb, KsMnb], \
                     columns = ["02. [Base Model] Multinomial Naive Bayes"])

# Save the model/classifier.
TmpPath = ROOT_PATH + r'\\' + MODEL_FILE_PATH + r'\\' + MODEL_MNB_FILE_NAME

with open(TmpPath, 'wb') as PickleFile:
    pickle.dump(ModelMnb, PickleFile)

# Load the model/classifier to ensure it is working fine.
TmpPath = ROOT_PATH + r'\\' + MODEL_FILE_PATH + r'\\' + MODEL_MNB_FILE_NAME

with open(TmpPath, 'rb') as PickleFile:
    ModelMnbTmp = pickle.load(PickleFile)

# Predict/Test using the loaded model/classifier.
t_pred = ModelMnbTmp.predict(X_test)

# Verification.
print("Confusion matrix: \n")
print(confusion_matrix(y_test, t_pred))

"""<a id=Step_07_ModelSgd></a>

#### <font color=Orange>03. [Base Model] SDGClassifier with Hinge Loss -> SVM.</font>

Note(s):
  * Support Vector Classifiers can be implemented by using the SGDClassifier with 'hinge' as the loss function.
  * Since the 'squared hinge loss' removes the possibility of negative class in the range, makes it the optimal choice for the loss function.
  * Cross Validation failed to yeild better results than the base model defined, hence skipped.
"""

# Create the object for the model/classifier.
ModelSgd = SGDClassifier(
                          loss='squared_hinge',
                          penalty='l2',
                          alpha=0.0001,
                          l1_ratio=0.15,
                          fit_intercept=True,
                          max_iter=1000,
                          tol=0.001,
                          shuffle=True,
                          verbose=1,
                          epsilon=0.1,
                          n_jobs=-1,
                          random_state=1,
                          learning_rate='optimal',
                          eta0=0.0,
                          power_t=0.5,
                          early_stopping=False,
                          validation_fraction=0.1,
                          n_iter_no_change=5,
                          class_weight=None,
                          warm_start=False,
                          average=False
                        ).fit(X_train, y_train)

# Get the 'cv_results_' into a Pandas data frame to display in a clean look.
# print(random_search.cv_results_)
MyDf = pd.DataFrame(random_search.cv_results_)

# Get the most important 'cv_results_' of the Pandas data frame for display.
MyDf[['param_alpha', 'params', 'mean_test_score']]

# # Note(s):
# #   * This part is NOT applicable for this model/classifier.

# Verification of available functions/methods.
# # dir(random_search)
# print("Best score    : {:.2f}".format(random_search.best_score_))
# print("Best params   : {:}".format(random_search.best_params_))
# print("Best estimator: {:}".format(random_search.best_estimator_))

# # Note(s):
# #   * This part is already done in the main cell.

# # Create the object for the model/classifier.
# ModelSgd = random_search.best_estimator_

# # Note(s):
# #   * This part is already done in the main cell.

# # Training/fitting the model/classifier (Using training data).
# ModelSgd.fit(X_train, y_train)

# Estimate the accuracy (or) Calculate the accuracy (or) Calculate the score of the model/classifier.
ScoreSgd = ModelSgd.score(X_test, y_test)

# Verification.
print("Score of the Model/Classifier: {:0.05f}".format(ScoreSgd))

# Predict/Test using the trained model/classifier.
y_pred = ModelSgd.predict(X_test)

# Verification.
# print("Actual    labels: {:}".format(y_test.tolist()))
# print("Predicted labels: {:}".format(y_pred))
# print((pd.DataFrame({'ActualLabels': y_test.tolist(), 'PredictedLabels': y_pred})).to_string(index=False))
(pd.DataFrame({'ActualLabels': y_test.tolist(), 'PredictedLabels': y_pred})).style.hide()

# Method-01: Evaluate the accuracy of the model/classifier.
AsSgd = accuracy_score(y_test, y_pred)

# Verification.
print("Accuracy Score: {:0.05f}".format(AsSgd))

# Method-02: Evaluate the accuracy of the model/classifier.
KsSgd = cohen_kappa_score(y_test, y_pred)

# Verification.
print("Kohen Kappa Score: {:0.05f}".format(KsSgd))

# Confusion matrix of the model/classifier.
CmSgd = confusion_matrix(y_test, y_pred)

# Verification.
print("Confusion matrix: \n")
print(CmSgd)

# Classification report of the model/classifier.
CrSgd = classification_report(y_test, y_pred)

# Verification.
print("Classification report: \n")
print(CrLrg)

# Dataframe with Accuracy score and Cohen Kappa score for later comparison.
DfSgd = pd.DataFrame([AsSgd, KsSgd], \
                     columns = ["03. [Base Model] SDG Classifier"])

# Save the model/classifier.
TmpPath = ROOT_PATH + r'\\' + MODEL_FILE_PATH + r'\\' + MODEL_SGD_FILE_NAME

with open(TmpPath, 'wb') as PickleFile:
    pickle.dump(ModelSgd, PickleFile)

# Load the model/classifier to ensure it is working fine.
TmpPath = ROOT_PATH + r'\\' + MODEL_FILE_PATH + r'\\' + MODEL_SGD_FILE_NAME

with open(TmpPath, 'rb') as PickleFile:
    ModelSgdTmp = pickle.load(PickleFile)

# Predict/Test using the loaded model/classifier.
t_pred = ModelSgdTmp.predict(X_test)

# Verification.
print("Confusion matrix: \n")
print(confusion_matrix(y_test, t_pred))

"""<a id=Step_07_ModelDtc></a>

#### <font color=Orange>04. [Base Model] Decision Tree Classifier with RandomizedSearchCV.</font>
"""

criterion = ['gini', 'entropy']
splitter = ['best', 'random']
max_depth = range(5, 200)
max_features = ['auto', 'sqrt', 'log2']

params =  {
            'criterion' : criterion,
            'splitter' : splitter,
            'max_depth' : max_depth,
            'max_features' : max_features
          }

random_search = RandomizedSearchCV(
                                    estimator = DecisionTreeClassifier(random_state = 1),
                                    param_distributions = params,
                                    n_iter = 100,
                                    cv = 3,
                                    n_jobs = -1,
                                    random_state = 1,
                                    verbose = 1
                                  ).fit(X_train.toarray(), y_train)

# Get the 'cv_results_' into a Pandas data frame to display in a clean look.
# print(random_search.cv_results_)
MyDf = pd.DataFrame(random_search.cv_results_)

# Get the most important 'cv_results_' of the Pandas data frame for display.
MyDf[['param_criterion', 'params', 'mean_test_score']]

# Verification of available functions/methods.
# dir(random_search)
print("Best score    : {:.2f}".format(random_search.best_score_))
print("Best params   : {:}".format(random_search.best_params_))
print("Best estimator: {:}".format(random_search.best_estimator_))

# Create the object for the model/classifier.
ModelDtc = random_search.best_estimator_

# # Note(s):
# #   * This part is already done using 'RandomizedSearchCV'.

# # Training/fitting the model/classifier (Using training data).
# ModelDtc.fit(X_train, y_train)

# Estimate the accuracy (or) Calculate the accuracy (or) Calculate the score of the model/classifier.
# ScoreDtc = ModelDtc.score(X_test, y_test)
ScoreDtc = ModelDtc.score(X_test.toarray(), y_test)

# Verification.
print("Score of the Model/Classifier: {:0.05f}".format(ScoreDtc))

# Predict/Test using the trained model/classifier.
# y_pred = ModelDtc.predict(X_test)
y_pred = ModelDtc.predict(X_test.toarray())

# Verification.
# print("Actual    labels: {:}".format(y_test.tolist()))
# print("Predicted labels: {:}".format(y_pred))
# print((pd.DataFrame({'ActualLabels': y_test.tolist(), 'PredictedLabels': y_pred})).to_string(index=False))
(pd.DataFrame({'ActualLabels': y_test.tolist(), 'PredictedLabels': y_pred})).style.hide()

# Method-01: Evaluate the accuracy of the model/classifier.
AsDtc = accuracy_score(y_test, y_pred)

# Verification.
print("Accuracy Score: {:0.05f}".format(AsDtc))

# Method-02: Evaluate the accuracy of the model/classifier.
KsDtc = cohen_kappa_score(y_test, y_pred)

# Verification.
print("Kohen Kappa Score: {:0.05f}".format(KsDtc))

# Confusion matrix of the model/classifier.
CmDtc = confusion_matrix(y_test, y_pred)

# Verification.
print("Confusion matrix: \n")
print(CmDtc)

# Classification report of the model/classifier.
CrDtc = classification_report(y_test, y_pred)

# Verification.
print("Classification report: \n")
print(CrDtc)

# Dataframe with Accuracy score and Cohen Kappa score for later comparison.
DfDtc = pd.DataFrame([AsDtc, KsDtc], \
                     columns = ["04. [Base Model] Decision Tree Classifier"])

# Save the model/classifier.
TmpPath = ROOT_PATH + r'\\' + MODEL_FILE_PATH + r'\\' + MODEL_DTC_FILE_NAME

with open(TmpPath, 'wb') as PickleFile:
    pickle.dump(ModelDtc, PickleFile)

# Load the model/classifier to ensure it is working fine.
TmpPath = ROOT_PATH + r'\\' + MODEL_FILE_PATH + r'\\' + MODEL_DTC_FILE_NAME

with open(TmpPath, 'rb') as PickleFile:
    ModelDtcTmp = pickle.load(PickleFile)

# Predict/Test using the loaded model/classifier.
t_pred = ModelDtcTmp.predict(X_test)

# Verification.
print("Confusion matrix: \n")
print(confusion_matrix(y_test, t_pred))

"""<a id=Step_07_ModelKnn></a>

#### <font color=Orange>05. [Base Model] k-Nearest Neighbors (k-NN) Classifier with RandomizedSearchCV.</font>
"""

n_neighbors = range(5, 100)
weights = ['uniform', 'distance']
algorithm = ['auto', 'ball_tree', 'kd_tree', 'brute']
leaf_size = range(30, 100)
p = range(1, 4)

params =  {
            'n_neighbors' : n_neighbors,
            'weights' : weights,
            'algorithm' : algorithm,
            'leaf_size' : leaf_size,
            'p'  : p
          }

random_search = RandomizedSearchCV(
                                    estimator = KNeighborsClassifier(n_jobs = -1),
                                    param_distributions = params,
                                    n_iter = 100,
                                    cv = 3,
                                    n_jobs = -1,
                                    random_state = 1,
                                    verbose = 1
                                  ).fit(X_train, y_train)

# Get the 'cv_results_' into a Pandas data frame to display in a clean look.
# print(random_search.cv_results_)
MyDf = pd.DataFrame(random_search.cv_results_)

# Get the most important 'cv_results_' of the Pandas data frame for display.
MyDf[['param_weights', 'param_p', 'param_n_neighbors', 'param_leaf_size', 'param_algorithm', 'params', 'mean_test_score']]

# Verification of available functions/methods.
# dir(random_search)
print("Best score    : {:.2f}".format(random_search.best_score_))
print("Best params   : {:}".format(random_search.best_params_))
print("Best estimator: {:}".format(random_search.best_estimator_))

# Create the object for the model/classifier.
ModelKnn = random_search.best_estimator_

# # Note(s):
# #   * This part is already done using 'RandomizedSearchCV'.

# # Training/fitting the model/classifier (Using training data).
# ModelKnn.fit(X_train, y_train)

# Estimate the accuracy (or) Calculate the accuracy (or) Calculate the score of the model/classifier.
ScoreKnn = ModelKnn.score(X_test, y_test)

# Verification.
print("Score of the Model/Classifier: {:0.05f}".format(ScoreKnn))

# Predict/Test using the trained model/classifier.
y_pred = ModelKnn.predict(X_test)

# Verification.
# print("Actual    labels: {:}".format(y_test.tolist()))
# print("Predicted labels: {:}".format(y_pred))
# print((pd.DataFrame({'ActualLabels': y_test.tolist(), 'PredictedLabels': y_pred})).to_string(index=False))
(pd.DataFrame({'ActualLabels': y_test.tolist(), 'PredictedLabels': y_pred})).style.hide()

# Method-01: Evaluate the accuracy of the model/classifier.
AsKnn = accuracy_score(y_test, y_pred)

# Verification.
print("Accuracy Score: {:0.05f}".format(AsKnn))

# Method-02: Evaluate the accuracy of the model/classifier.
KsKnn = cohen_kappa_score(y_test, y_pred)

# Verification.
print("Kohen Kappa Score: {:0.05f}".format(KsKnn))

# Confusion matrix of the model/classifier.
CmKnn = confusion_matrix(y_test, y_pred)

# Verification.
print("Confusion matrix: \n")
print(CmKnn)

# Classification report of the model/classifier.
CrKnn = classification_report(y_test, y_pred)

# Verification.
print("Classification report: \n")
print(CrKnn)

# Dataframe with Accuracy score and Cohen Kappa score for later comparison.
DfKnn = pd.DataFrame([AsKnn, KsKnn], \
                     columns = ["05. [Base Model] k-NN Classifier"])

# Save the model/classifier.
TmpPath = ROOT_PATH + r'\\' + MODEL_FILE_PATH + r'\\' + MODEL_KNN_FILE_NAME

with open(TmpPath, 'wb') as PickleFile:
    pickle.dump(ModelKnn, PickleFile)

# Load the model/classifier to ensure it is working fine.
TmpPath = ROOT_PATH + r'\\' + MODEL_FILE_PATH + r'\\' + MODEL_KNN_FILE_NAME

with open(TmpPath, 'rb') as PickleFile:
    ModelKnnTmp = pickle.load(PickleFile)

# Predict/Test using the loaded model/classifier.
t_pred = ModelKnnTmp.predict(X_test)

# Verification.
print("Confusion matrix: \n")
print(confusion_matrix(y_test, t_pred))

"""<a id=Step_07_ModelSvm></a>

#### <font color=Orange>06. [Base Model] Support Vector Machine (SVM) Classifier.</font>
"""

# Create the object for the model/classifier.
ModelSvm = SVC(kernel='linear')

# Training/fitting the model/classifier (Using training data).
ModelSvm.fit(X_train, y_train)

# Estimate the accuracy (or) Calculate the accuracy (or) Calculate the score of the model/classifier.
ScoreSvm = ModelSvm.score(X_test, y_test)

# Verification.
print("Score of the Model/Classifier: {:0.05f}".format(ScoreSvm))

# Predict/Test using the trained model/classifier.
y_pred = ModelSvm.predict(X_test)

# Verification.
# print("Actual    labels: {:}".format(y_test.tolist()))
# print("Predicted labels: {:}".format(y_pred))
# print((pd.DataFrame({'ActualLabels': y_test.tolist(), 'PredictedLabels': y_pred})).to_string(index=False))
(pd.DataFrame({'ActualLabels': y_test.tolist(), 'PredictedLabels': y_pred})).style.hide()

# Method-01: Evaluate the accuracy of the model/classifier.
AsSvm = accuracy_score(y_test, y_pred)

# Verification.
print("Accuracy Score: {:0.05f}".format(AsSvm))

# Method-02: Evaluate the accuracy of the model/classifier.
KsSvm = cohen_kappa_score(y_test, y_pred)

# Verification.
print("Kohen Kappa Score: {:0.05f}".format(KsSvm))

# Confusion matrix of the model/classifier.
CmSvm = confusion_matrix(y_test, y_pred)

# Verification.
print("Confusion matrix: \n")
print(CmSvm)

# Classification report of the model/classifier.
CrSvm = classification_report(y_test, y_pred)

# Verification.
print("Classification report: \n")
print(CrSvm)

# Dataframe with Accuracy score and Cohen Kappa score for later comparison.
DfSvm = pd.DataFrame([AsSvm, KsSvm], \
                     columns = ["06. [Base Model] SVM Classifier"])

# Save the model/classifier.
TmpPath = ROOT_PATH + r'\\' + MODEL_FILE_PATH + r'\\' + MODEL_SVM_FILE_NAME

with open(TmpPath, 'wb') as PickleFile:
    pickle.dump(ModelSvm, PickleFile)

# Load the model/classifier to ensure it is working fine.
TmpPath = ROOT_PATH + r'\\' + MODEL_FILE_PATH + r'\\' + MODEL_SVM_FILE_NAME

with open(TmpPath, 'rb') as PickleFile:
    ModelSvmTmp = pickle.load(PickleFile)

# Predict/Test using the loaded model/classifier.
t_pred = ModelSvmTmp.predict(X_test)

# Verification.
print("Confusion matrix: \n")
print(confusion_matrix(y_test, t_pred))

"""<a id=Step_07_ModelSvc></a>

#### <font color=Orange>07. [Ensemble Method] Soft Voting Classifier.</font>
"""

estimators = [
              ('LRG', ModelLrg),
              ('MNB', ModelMnb),
              ('DTC', ModelDtc),
              ('KNN', ModelKnn),
             ]

# Verification.
print("Estimators: \n")
print(estimators)

# Create the object for the model/classifier.
ModelSvc = VotingClassifier(
                            estimators=estimators,
                            voting='soft',
                            n_jobs=-1,
                            flatten_transform=True,
                            verbose=1,
                           ).fit(X_train, y_train)

# ModelSvc.fit(X_train, y_train)

# # Note(s):
# #   * This part is already done in the main cell.

# # Create the object for the model/classifier.
# ModelSvc = random_search.best_estimator_

# # Note(s):
# #   * This part is already done in the main cell.

# # Training/fitting the model/classifier (Using training data).
# ModelSvc.fit(X_train, y_train)

# Estimate the accuracy (or) Calculate the accuracy (or) Calculate the score of the model/classifier.
ScoreSvc = ModelSvc.score(X_test, y_test)

# Verification.
print("Score of the Model/Classifier: {:0.05f}".format(ScoreSvc))

# Predict/Test using the trained model/classifier.
y_pred = ModelSvc.predict(X_test)

# Verification.
# print("Actual    labels: {:}".format(y_test.tolist()))
# print("Predicted labels: {:}".format(y_pred))
# print((pd.DataFrame({'ActualLabels': y_test.tolist(), 'PredictedLabels': y_pred})).to_string(index=False))
(pd.DataFrame({'ActualLabels': y_test.tolist(), 'PredictedLabels': y_pred})).style.hide()

# Method-01: Evaluate the accuracy of the model/classifier.
AsSvc = accuracy_score(y_test, y_pred)

# Verification.
print("Accuracy Score: {:0.05f}".format(AsSvc))

# Method-02: Evaluate the accuracy of the model/classifier.
KsSvc = cohen_kappa_score(y_test, y_pred)

# Verification.
print("Kohen Kappa Score: {:0.05f}".format(KsSvc))

# Confusion matrix of the model/classifier.
CmSvc = confusion_matrix(y_test, y_pred)

# Verification.
print("Confusion matrix: \n")
print(CmSvc)

# Classification report of the model/classifier.
CrSvc = classification_report(y_test, y_pred)

# Verification.
print("Classification report: \n")
print(CrSvc)

# Dataframe with Accuracy score and Cohen Kappa score for later comparison.
DfSvc = pd.DataFrame([AsSvc, KsSvc], \
                     columns = ["07. [Ensemble Method] Soft Voting Classifier"])

# Save the model/classifier.
TmpPath = ROOT_PATH + r'\\' + MODEL_FILE_PATH + r'\\' + MODEL_SVC_FILE_NAME

with open(TmpPath, 'wb') as PickleFile:
    pickle.dump(ModelSvc, PickleFile)

# Load the model/classifier to ensure it is working fine.
TmpPath = ROOT_PATH + r'\\' + MODEL_FILE_PATH + r'\\' + MODEL_SVC_FILE_NAME

with open(TmpPath, 'rb') as PickleFile:
    ModelSvcTmp = pickle.load(PickleFile)

# Predict/Test using the loaded model/classifier.
t_pred = ModelSvcTmp.predict(X_test)

# Verification.
print("Confusion matrix: \n")
print(confusion_matrix(y_test, t_pred))

"""<a id=Step_07_ModelStk></a>

#### <font color=Orange>08. [Ensemble Method] Stacking Classifier with XGBClassifier as the "Final Estimator" or "Meta Learner".</font>
"""

# Create the object of XGB Classifier.
Xgb = xgboost.XGBClassifier()

# Verification.
print("XGB Classifier: \n")
print(Xgb)

# Create the object for the model/classifier.
ModelStk = StackingClassifier(
                                estimators=estimators + [('svm', ModelSgd)],
                                final_estimator=Xgb,
                                n_jobs=-1,
                                verbose=1,
                             ).fit(X_train, y_train)

# ModelStack.fit(X_train, y_train)

# # Note(s):
# #   * This part is already done in the main cell.

# # Create the object for the model/classifier.
# ModelStk = random_search.best_estimator_

# # Note(s):
# #   * This part is already done in the main cell.

# # Training/fitting the model/classifier (Using training data).
# ModelStk.fit(X_train, y_train)

# Estimate the accuracy (or) Calculate the accuracy (or) Calculate the score of the model/classifier.
ScoreStk = ModelStk.score(X_test, y_test)

# Verification.
print("Score of the Model/Classifier: {:0.05f}".format(ScoreStk))

# Predict/Test using the trained model/classifier.
y_pred = ModelStk.predict(X_test)

# Verification.
# print("Actual    labels: {:}".format(y_test.tolist()))
# print("Predicted labels: {:}".format(y_pred))
# print((pd.DataFrame({'ActualLabels': y_test.tolist(), 'PredictedLabels': y_pred})).to_string(index=False))
(pd.DataFrame({'ActualLabels': y_test.tolist(), 'PredictedLabels': y_pred})).style.hide()

# Method-01: Evaluate the accuracy of the model/classifier.
AsStk = accuracy_score(y_test, y_pred)

# Verification.
print("Accuracy Score: {:0.05f}".format(AsStk))

# Method-02: Evaluate the accuracy of the model/classifier.
KsStk = cohen_kappa_score(y_test, y_pred)

# Verification.
print("Kohen Kappa Score: {:0.05f}".format(KsStk))

# Confusion matrix of the model/classifier.
CmStk = confusion_matrix(y_test, y_pred)

# Verification.
print("Confusion matrix: \n")
print(CmStk)

# Classification report of the model/classifier.
CrStk = classification_report(y_test, y_pred)

# Verification.
print("Classification report: \n")
print(CrStk)

# Dataframe with Accuracy score and Cohen Kappa score for later comparison.
DfStk = pd.DataFrame([AsStk, KsStk], \
                     columns = ["08. [Ensemble Method] Stacking Classifier"])

# Save the model/classifier.
TmpPath = ROOT_PATH + r'\\' + MODEL_FILE_PATH + r'\\' + MODEL_STK_FILE_NAME

with open(TmpPath, 'wb') as PickleFile:
    pickle.dump(ModelStk, PickleFile)

# Load the model/classifier to ensure it is working fine.
TmpPath = ROOT_PATH + r'\\' + MODEL_FILE_PATH + r'\\' + MODEL_STK_FILE_NAME

with open(TmpPath, 'rb') as PickleFile:
    ModelStkTmp = pickle.load(PickleFile)

# Predict/Test using the loaded model/classifier.
t_pred = ModelStkTmp.predict(X_test)

# Verification.
print("Confusion matrix: \n")
print(confusion_matrix(y_test, t_pred))

"""<a id=Step_07_MC></a>

#### <font color=Orange>Model Comparision.</font>
"""

# Compare the Accuracy scores and Kohen Kappa scores across all models.
ModelCmp = pd.concat([DfLrg, DfMnb, DfSgd, DfDtc, DfKnn, DfSvm, DfSvc, DfStk], axis = 1)

# Create the index for the data frame.
ModelIdx = pd.Index(["AccuracyScore", "KohenKappaScore"])

# Set the index for the data frame.
ModelCmp = ModelCmp.set_index(ModelIdx)


# Verification.
ModelCmp

"""<a id=Step_07_CO></a>

#### <font color=Orange>Check for Overfitting.</font>
"""

# Method-01:

# Evaluate model.
CvScores = cross_val_score(ModelLrg, X, y, cv = 10)

# Model performance.
np.set_printoptions(precision=3)
print(CvScores)
print("Cross validation score: {:.3f}".format(CvScores.mean()))

# Method-02:

# Prepare the cross validation.
Cv = KFold(n_splits = 10, random_state = 1, shuffle = True)

# Evaluate model.
CvScores = cross_val_score(ModelLrg, X, y, scoring = 'accuracy', cv = Cv, n_jobs = -1)

# Model performance.
# print("Accuracy: {:.3f} ({:.3f})".format(mean(CvScores), std(CvScores)))
print("Cross validation score: {:.3f}".format(CvScores.mean()))

"""<a href="#Contents" style="float:right">[Contents]</a>

<a id=Step_08></a>

## <font color=Green>Step-08: AIML Model Testing.</font>

<a id=Step_08_Py></a>

### <font color=Red>Python Libraries.</font>
"""

# Basic imports.
import re
import time

# MS-Excel related imports.
import openpyxl
from openpyxl import load_workbook

"""
Duplicate.
To sync with split file model i.e. separate files for Data, Model, WebApp, GuiApp.
"""

# NLTK library imports.
import nltk
nltk.download('stopwords')
from nltk.corpus import stopwords
# nltk.download('wordnet')
# nltk.download('punkt')
# from nltk.tokenize import WordPunctTokenizer
# from nltk.stem import WordNetLemmatizer
# from nltk import sent_tokenize
# from nltk import word_tokenize
# from string import punctuation

"""<a id=Step_08_Co></a>

### <font color=Red>Constants.</font>
"""

# Path and file(s).
ROOT_PATH = r"C:\Users\kalya\Desktop\RVHackathon\2024-03-02 ResumeMatch"
INPUT_DATA_EXCEL_FILE_PATH = r"C:\Users\kalya\Desktop\RVHackathon\2024-03-02 ResumeMatch\01_Input\Data"
INPUT_DATA_EXCEL_FILE_NAME = r"ResumeDataSet_BrandNew.xlsx"

# Data file related.
WORKSHEET_NAME = r"ResumeDataSet"
CATEGORY_COL_NUM = 2
LABEL_COL_NUM = 4

"""
Duplicate.
To sync with split file model i.e. separate files for Data, Model, WebApp, GuiApp.
"""

# Keep the words having length greater than or equal to this value.
WORD_LENGTH_TO_KEEP = 3

"""<a id=Step_08_Va></a>

### <font color=Red>Variables.</font>
"""

"""
Duplicate.
To sync with split file model i.e. separate files for Data, Model, WebApp, GuiApp.
"""

# All the special characters in the order of the ASCII chart.
# Note(s):
#   * Excluded the character '+', because we need the word 'C++'.
SpecialcharList = ['!', '"', '#', '$', '%', '&', "'", '(', ')', '*', ',', '-', '.', '/', ':', ';', '<', '=', '>', '?', '@', '[', '\\', ']', '^', '_', '`', '{', '|', '}', '~' ]

# # Verification.
# print(len(SpecialcharList))

"""
Duplicate.
To sync with split file model i.e. separate files for Data, Model, WebApp, GuiApp.
"""

"""
This variable initialization code should not be uncommented.
If so the actual initialized and filled variable will be set to a blank.
"""

# # Python set to store common words across the classes.
# CommonWordSet = set()

# Python list to store words which doesn't carry any weithtage.
# The developer/programmer has to fill this list.
# Used in the User Defined Function (UDF) 'RemoveNoWeightWords'.
NoWeightWordList = [
                    'college', 'completed', 'computer', 'cricket', 'crecket',
                    'disctrict', 'engineering', 'experience', 'involved', 'issue',
                    'issues', 'june', 'learning', 'less', 'like',
                    'ltd', 'maharashtra', 'mumbai', 'ofice', 'process',
                    'project', 'pune', 'pvt', 'requirements', 'responsibility',
                    'responsibilities', 'role', 'roles', 'software', 'system',
                    'tamil', 'technology', 'used', 'user', 'users',
                    'using', 'work', 'worked', 'year'
                   ]
# Sort the list in ascending order.
NoWeightWordList.sort(reverse = False)

# Global variable to be used when testing with test data.
TestDataRowsPerLabel = 0

"""
Duplicate.
To sync with split file model i.e. separate files for Data, Model, WebApp, GuiApp.
"""

"""
This variable initialization code should not be uncommented.
If so the actual initialized and filled variable will be set to a blank.
"""

# # Get the unique values of 'ClassLabel' column as a Python list.
# ClassLabelList = list()

# # Get the unique values of class names i.e. 'Position' column as a Python list.
# ClassNameList = list()

"""<a id=Step_08_Ma></a>

### <font color=Red>Main Code.</font>

<a id=Step_08_C01></a>

#### <font color=Orange>Case-01: Testing with Test Data.</font>

Note(s):
* After splitting train and test rows of data, we have kept the test data in a list.
* In this section, we are going to verify the model performance using this test part of the data.
"""

# Iterate through the cells of the 'PdDfTestActualDataList' list.
# After splitting train and test rows, we have kept the test data in this list.
# It is the time to verify the model performance using this test part of the data.
for Idx in range(len(PdDfTestActualDataList)):
    # User Defined Function (UDF) call to predict the Label, Class Probability (CP) from the given text.
    Prediction, Cp = PredictText(ModelStk, PdDfTestActualDataList[Idx])

    # Result display.
    print("Class Probability: {:2.1f}%" \
          .format(Cp[Prediction] * 100))
    print("Actual Label     : {:}, Predicted Label  : {:}" \
          .format(PdDfTestClassLabelList[Idx], Prediction))
    print("Actual Category  : {:}, Predicted Category: {:}" \
          .format(ClassNameList[PdDfTestClassLabelList[Idx]], ClassNameList[Prediction]))

    # Verification of the correctness of the prediction by the model.
    if PdDfTestClassLabelList[Idx] == Prediction:
        print("\u2714 " + "Right Prediction.\n")
    else:
        print("\u2716 " + "Wrong Prediction.\n")

    # ONLY for formatted display.
    if (Idx + 1) % TestdataRowsPerLabel == 0:
        print()

"""<a id=Step_08_C02></a>

#### <font color=Orange>Case-02: Testing with Brand New Data.</font>

Note(s):
* Actually, the original data file "`01_UpdatedResumeDataSet.csv`" was modified manually by adding few rows of data and by removing another few rows of data. In this process, created the data files "`02_ResumeDataSet.xlsx`", "`03_ResumeDataSet.xlsx`" and "`04_ResumeDataSet.xlsx`".
* The data file "`04_ResumeDataSet.xlsx`" was devided into two data files "`ResumeDataSet_TrainTest.xlsx`" and "`ResumeDataSet_BrandNew.xlsx`".  The first one "`ResumeDataSet_TrainTest.xlsx`" was used for the AMIL model training and testing.
* In this section, we are going to use the second one "`ResumeDataSet_BrandNew.xlsx`" to test the AIML model.
"""

# Load the data file i.e. MS-Excel workbook.
TmpPath = INPUT_DATA_EXCEL_FILE_PATH + r'\\' + INPUT_DATA_EXCEL_FILE_NAME
Workbook = load_workbook(filename = TmpPath)
time.sleep(2)

# Select the 'Active' worksheet.
Worksheet = Workbook.active

# Get the number of rows and number of columns of the worksheet.
MinRow = Worksheet.min_row
MinCol = Worksheet.min_column
MaxRow = Worksheet.max_row
MaxCol = Worksheet.max_column

# Verification.
print("Min Row: {:03d}, Min Col: {:03d}".format(MinRow, MinCol))
print("Max Row: {:03d}, Max Col: {:03d}".format(MaxRow, MaxCol))

# Iterate through worksheet's rows and columns by leaving the header row.
# Get the resume text, clean it up and write into a new column of the same row.
for Row in range(MinRow + 1, MaxRow + 1):
    # Get the content of the cell i.e. resume text.
    CellContent = Worksheet.cell(row = Row, column = MaxCol).value
    Actualcategory = Worksheet.cell(row = Row, column = CATEGORY_COL_NUM).value
    ActualLabel = Worksheet.cell(row = Row, column = LABEL_COL_NUM).value

    # User Defined Function (UDF) call to predict the Label, Class Probability (CP) from the given text.
    Prediction, Cp = PredictText(ModelStk, CellContent)

    # Result display.
    print("Class Probability: {:2.1f}%" \
          .format(Cp[Prediction] * 100))
    print("Actual Label     : {:}, Predicted Label  : {:}" \
          .format(ActualLabel, Prediction))
    print("Actual Category  : {:}, Predicted Category: {:}" \
          .format(Actualcategory, ClassNameList[Prediction]))

    # Verification of the correctness of the prediction by the model.
    if ActualLabel == Prediction:
        print("\u2714 " + "Right Prediction.\n")
    else:
        print("\u2716 " + "Wrong Prediction.\n")

# Close the data file i.e. MS-Excel workbook.
Workbook.close()
time.sleep(2)

"""<a href="#Contents" style="float:right">[Contents]</a>

<a id=Step_09></a>

## <font color=Green>Step-09: Deployment Process.</font>

Note(s):
* Go to the directory "04_Deployment".
* In this directory, we have a Python file (BackEnd.py), fifteen text data files and one sub-directory (Templates). The Python file 'BackEnd.py' is the FastAPI deployment and main file. The 'Templates' directory contains two HTML files one is to get input from the user and the other to output the results.  Also, we have fifteen text data files corresponding to fifteen data labels (0 to 14).  These data files are created by getting one row of data under 'Resume' column of the file "ResumeDataSet_BrandNew.xlsx" for one data label.  We use these text data files to test the deployment process.

01. Open a command prompt in the `'04_Deployment'` directory.  Type the command `'uvicorn BackEnd:App --reload'`.

<img src="01_Input\Support\Deployment_01.jpg" align="left" width="859" height="338">

02. After pressing 'Enter' key, we get some info i.e. `INFO: Application startup complete.`.  Also we get `INFO: Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)`.  Copy and paste the string `http://127.0.0.1:8000' in a browser.

<img src="01_Input\Support\Deployment_02.jpg" align="left" width="859" height="338">

03. A web page opens in the web browser and will be as shown in the following.

<img src="01_Input\Support\Deployment_03.jpg"  align="left" width="859" height="548">

04. Click on the button 'Choose File'.  A browser window will be opened. Select any one out of the fifteen text data files.  Note that the fifteen text data files should be in the same location as the 'BackEnd.py'.

<img src="01_Input\Support\Deployment_04.jpg" align="left" width="526" height="440">

<img src="01_Input\Support\Deployment_05.jpg"  align="left" width="859" height="548">

05. Click on the button 'Submit'.  Then,
  * The text file will be uploaded.
  * The 'BackEnd.py' file receive this file.
  * The content of the text file will be cleaned.
  * Then the cleaned-up text will be sent to the AIML model.
  * The AIML model will give a prediction along with the Confidence Score.
  * The results will be displayed on the web browser as shown.

<img src="01_Input\Support\Deployment_06.jpg" align="left" width="859" height="548">

<a href="#Contents" style="float:right">[Contents]</a>

<a id=Step_10></a>

## <font color=Green>Step-10: Windows GUI Application.</font>

Note(s):
* When executed the last cell of this step (Step-09: Windows GUI Application), a GUI window will be opened as shown in the following image(s):
* Go to the directory "01_Input\Data" and open the file "ResumeDataSet_BrandNew.xlsx".
* Copy any cell under the column with name "Resume". Paste the content in the text field under "Enter resume text to predict" of the GUI window.
* Click on the submit button.
* The string "This resume is suitable for the position: ..." should be displayed in the text field under "Predicted category" of the GUI window. The "..." indicates the actual prediction string depending on the text we have pasted.  This string should match with the cell content under the column with name "Position" of the excel file.
* A confidence score value will also be displayed on the GUI window.  Generally this value should be greater than 90%.
* This GUI window can be used any number of types by pasting new text and then by clicking on "Submit" button.
* To exit the GUI window, click on the "Exit" button.

<img src="01_Input\Support\GUI_Window_01.jpg" align="left" width="722" height="452">

<img src="01_Input\Support\GUI_Window_02.jpg" align="left" width="722" height="452">

<a id=Step_10_Py></a>

### <font color=Red>Python Libraries.</font>
"""

# Windows GUI Library Imports.
from tkinter import *
from tkinter import messagebox
from tkinter import ttk

# Image processing related imports.
from PIL import Image, ImageTk

"""<a id=Step_10_Co></a>

### <font color=Red>Constants.</font>
"""

# Display screen.
DISP_RES_WIDTH = 1280
DISP_RES_HEIGHT = 720

# Splash Screen.

# Path and file(s).
ROOT_PATH = r"C:\Users\kalya\Desktop\RVHackathon\2024-03-02 ResumeMatch"
SPLASH_IMAGE_FILE_PATH = r"01_Input\Support"
SPLASH_IMAGE_FILE_NAME = r"SplashScreen.jpg"

# Time.
SPLASH_TIME = 3000

# Size.
SPLASH_WIDTH = 640
SPLASH_HEIGHT = 360

# Main Window.

# Path and file(s).
ROOT_PATH = r"C:\Users\kalya\Desktop\RVHackathon\2024-03-02 ResumeMatch"
MAIN_ICON_FILE_PATH = r"01_Input\Support"
MAIN_JPG_ICON_FILE_NAME = r"PyIcon.jpg"
MAIN_ICO_ICON_FILE_NAME = r"PyIcon.ico"
MAIN_TITLE = r"ResumeMatch Tool"

# Size.
MAIN_WIDTH = 960
MAIN_HEIGHT = 540
MAIN_HEAD_HEIGHT = 30
MAIN_PIVOT_X = 0
MAIN_PIVOT_Y = 0

# Tk Widgets.

# Size.
LABEL01_TITLE = r"Enter resume text to predict:"
LABEL02_TITLE = r"Predicted category:"
LABEL03_TITLE = r"Confidence score: 000.00%"
WIDGET_LABEL_HEIGHT = 21
WIDGET_ENTRY_HEIGHT = 19
WIDGET_TEXT_HEIGHT = 17
WIDGET_BUTTON_HEIGHT = 26
WIDGET_HORIZONTAL_GAP = 20
WIDGET_VERTICLE_GAP = 20

"""<a id=Step_10_Va></a>

### <font color=Red>Variables.</font>
"""

# Global variables.
PredictionForGUI = -1
CpForGUI = -1

"""<a id=Step_10_Ma></a>

### <font color=Red>Main Code.</font>

<a id=Step_10_LocalUdfs></a>

#### <font color=Orange>Local User Defined Functions (UDFs).</font>
"""

# Splash Screen.
def FadeOut():
    Alpha = SplashWindow.attributes("-alpha")

    if Alpha > 0:
        Alpha -= .1
        SplashWindow.attributes("-alpha", Alpha)
        SplashWindow.after(100, FadeOut)
    else:
        SplashWindow.destroy()

# Main window and Frame window (to keep different Tkinter widgets like Label, Entry, Button etc.)
def ModelManager():
    global PredictionForGUI
    global CpForGUI


    # Get the text entered in the Tkinter 'Text' widget.
    TextToPredict = str(MainWinText01.get("1.0", "end-1c"))

#     """
#     Note(s):
#     # Text.get("1.0", END)
#     # * "1.0" means that the input should be read from line one, character zero (ie: the very first character).
#     # * END is an imported constant which is set to the string "end".
#     # * The END part means to read until the end of the text box is reached.
#     # * The only issue with this is that it actually adds a newline to our input.
#     # * So, in order to fix it we should change END to "end-1c".
#     # * The '-1c' deletes 1 character, while '-2c' would mean delete two characters, and so on.
#     """

#     # Get the text of the Tkinter 'Text' widget.
#     # If the text is empty then display a message box otherwise process it.
#     if len(TextToPredict) > 0:
#         # User Defined Function (UDF) call to predict the Label, Class Probability (CP) from the given text.
#         PredictionForGUI, CpForGUI = PredictText(ModelStk, TextToPredict)

#         CpForGuiStr = str("{:2.2f}%".format(CpForGUI[PredictionForGUI] * 100))
#         CpForGuiStr = LABEL03_TITLE[0:18] + CpForGuiStr.zfill(7)

#         # Make the state 'NORMAL' before inserting/removing any text to the 'Text ' widget.
#         MainWinText02.configure(state=NORMAL)

#         # If there is any thing of the previously predicted label, then reset it i.e.Tkinter 'Text' widget.
#         MainWinText02.delete("1.0", END)

#         # Set the corresponding info of the predicted label to the Tkinter 'Text' widget.
#         MainWinText02.insert(END, str(LabelNumVsResultDict[PredictionForGUI]))

#         # Make the 'Text' widget scroll to the end of the text.
#         MainWinText02.see(END)

#         # Make the state 'DISABLED' after inserting/removing any text to the 'Text' widget.
#         MainWinText02.configure(state=DISABLED)

#         # Set the corresponding Class Probability of the predicted Label to the Tkinter 'Label' widget.
#         MainWinLabel03["text"]= CpForGuiStr
#     else:
#         # Make the state 'NORMAL' before inserting/removing any text to the 'Text ' widget.
#         MainWinText02.configure(state=NORMAL)

#         # If there is any thing of the previously predicted label, then reset it i.e.Tkinter 'Text' widget.
#         MainWinText02.delete("1.0", END)

#         # Make the state 'DISABLED' after inserting/removing any text to the 'Text' widget.
#         MainWinText02.configure(state=DISABLED)

#         # Reset the corresponding Class Probability of the predicted Label to the Tkinter 'Label' widget.
#         MainWinLabel03["text"]= LABEL03_TITLE

#         # Display the message with appropriate message text.
#         messagebox.showwarning("Info", "Prediction text field is empty or invalid text.")


    # Get the text of the Tkinter 'Text' widget.
    # If the text is empty then display a message box otherwise process it.
    if len(TextToPredict) > 0:
        # User Defined Function (UDF) call to predict the Label, Class Probability (CP) from the given text.
        PredictionForGUI, CpForGUI = PredictText(ModelStk, TextToPredict)

        CpForGuiStr = str("{:2.2f}%".format(CpForGUI[PredictionForGUI] * 100))
        CpForGuiStr = LABEL03_TITLE[0:18] + CpForGuiStr.zfill(7)

        # If there is any thing of the previously predicted label, then reset it i.e.Tkinter 'Text' widget.
        MainWinEntry01.delete(0, END)

        # Set the corresponding info of the predicted label to the Tkinter 'Text' widget.
        MainWinEntry01.insert(0, str(LabelNumVsResultDict[PredictionForGUI]))

        # Set the corresponding Class Probability of the predicted Label to the Tkinter 'Label' widget.
        MainWinLabel03["text"]= CpForGuiStr
    else:
        # If there is any thing of the previously predicted label, then reset it i.e.Tkinter 'Text' widget.
        MainWinEntry01.delete(0, END)

        # Reset the corresponding Class Probability of the predicted Label to the Tkinter 'Label' widget.
        MainWinLabel03["text"]= LABEL03_TITLE

        # Display the message with appropriate message text.
        messagebox.showwarning("Info", "Prediction text field is empty or invalid text.")


    # return None

# def CopyToClipboard():
#     global PredictionForGUI
#     global CpForGuI


#     # Clear the clipboard.
#     MainWindow.clipboard_clear()

#     # Update the clipboard with the content.
#     MainWwindow.clipboard_append(str(LabelNumVsResultDict[PredictionForGUI]))

#     # The copied content stays on the clipboard even after the main window is closed.
#     MainWindow.update()


#     # return None

# def OpenURL():
#     # Display the message with appropriate message text.
#     messagebox.showwarning("Info", "This feature is to be implemented.")

#     return None

def ExitCallBack():
    MainWindow.destroy()

# Results list in the order of 'ClassLabelList'.
ResultList = list()

# Iterate through the cells of the 'ClassLabelList' list.
for Idx in range(len(ClassLabelList)):
    ResultList.append("This resume is suitable for the position: {:s}".format(ClassNameList[Idx]))

# Create a Python dictionary variable with 'ClassLabelList' list and 'ResultList'.
LabelNumVsResultDict = dict(zip(ClassLabelList, ResultList))


# Verification.
print(LabelNumVsResultDict)

# Convert '.jpg' to '.ico'.
TmpPath = ROOT_PATH + r'\\' + MAIN_ICON_FILE_PATH + r'\\' + MAIN_JPG_ICON_FILE_NAME
Img = Image.open(TmpPath)

TmpPath = ROOT_PATH + r'\\' + MAIN_ICON_FILE_PATH + r'\\' + MAIN_ICO_ICON_FILE_NAME
Img.save(TmpPath, format = 'ICO', sizes = [(16, 16)])

# Splash screen followed by a frame window.
# The frame window is to keep different widgets like Button, Label, Text etc.


##################
# Splash window. #
##################
SplashWindow = Tk()


# Actual screen width and height.
ScrWidth = SplashWindow.winfo_screenwidth()
ScrHeight = SplashWindow.winfo_screenheight()

# Prepare the GUI condition.
GuiCondition = ScrWidth < (DISP_RES_WIDTH) or ScrHeight < (DISP_RES_HEIGHT)

# Prepare error string by having the info regarding current screen resolution.
Str1 = "Current screen resolution is: (Width, Height) = ({:04d}, {:04d})". \
        format(ScrWidth, ScrHeight)
Str2 = "Minimum screen resolution required is: (Width, Height) = ({:04d}, {:04d})". \
        format(DISP_RES_WIDTH, DISP_RES_HEIGHT)
ErrorString = Str1 + '\n' + Str2

# Stop execution of code from this point onwards in case the screen resolution requirement is not meeting.
assert not GuiCondition, ErrorString


# Set X,Y coordinates for the Splash window.
SplashX = (ScrWidth - SPLASH_WIDTH) // 2
SplashY = (ScrHeight - SPLASH_HEIGHT) // 2
Size = '%dx%d+%d+%d' %(SPLASH_WIDTH, SPLASH_HEIGHT, SplashX, SplashY)
SplashWindow.geometry(Size)

# Splash window will not have a title or a border.
# It can not be moved or closed via general means.
SplashWindow.overrideredirect(True)

# Create the Splash frame, a container, which is responsible
# for arranging the position of other widgets.
SplashFrame = Frame(SplashWindow)
SplashFrame.pack(side = BOTTOM)

# Place an image on the Splash frame.
TmpPath = ROOT_PATH + r'\\' + SPLASH_IMAGE_FILE_PATH + r'\\' + SPLASH_IMAGE_FILE_NAME
SplashImage = Image.open(TmpPath)
PhotoImage = ImageTk.PhotoImage(SplashImage)
SplashLabel = Label(SplashWindow, image = PhotoImage)
SplashLabel.pack()

# Destroy the Splash window (widget). Time in milli seconds.
# SplashWindow.after(5000, lambda: Splashwindow.destroy()
SplashWindow.after(SPLASH_TIME, FadeOut)
SplashWindow.mainloop()


# ################
# # Main window. #
# ################
MainWindow = Tk()


# Main window icon.
TmpPath = ROOT_PATH + r'\\' + MAIN_ICON_FILE_PATH + r'\\' + MAIN_ICO_ICON_FILE_NAME
MainWindow.iconbitmap(TmpPath)

# Main window title.
MainWindow.title(MAIN_TITLE)

# Main window - Disable resizing.
MainWindow.resizable(width=False, height=False)

# Actual screen width and height
ScrWidth = MainWindow.winfo_screenwidth()
ScrHeight = MainWindow.winfo_screenheight()

# Main window width and height.
MainWindowWidth = MAIN_WIDTH
MainWindowHeight = MAIN_HEIGHT + MAIN_HEAD_HEIGHT


# Set X,Y coordinates for the Main window.
MainX = (ScrWidth - MainWindowWidth) // 2
MainY = (ScrHeight - MainWindowHeight) // 2
MainY -= MAIN_HEAD_HEIGHT
Size = "%dx%d+%d+%d" %(MainWindowWidth, MainWindowHeight, MainX, MainY)
MainWindow.geometry(Size)
print("Screen (Width, Height) = ({:04d}, {:04d})".format(ScrWidth, ScrHeight))
print()
print("Window (Width, Height) = ({:04d}, {:04d})".format(MainWindowWidth, MainWindowHeight))
print("Window           (X, Y) = ({:04d}, {:04d})".format(int(MainX), int(MainY)))
print()

# Create the Main frame, a container, which is responsible
# for arranging the position of other widgets.
MainFrame = Frame(MainWindow)
MainFrame.pack(side = BOTTOM)


########################
# Main window widgets. #
########################

# Tkinter Label widget.
MainWinLabelA = Label(MainWindow, bg = "#F5F5F5", bd = 4, relief = RAISED, text ="")
X1 = MAIN_PIVOT_X + WIDGET_HORIZONTAL_GAP
Y1 = WIDGET_VERTICLE_GAP
W1 = MainWindowWidth - (WIDGET_HORIZONTAL_GAP * 2)
H1 = (MainWindowHeight - (WIDGET_VERTICLE_GAP * 4)) // 2
H1 = H1 + (WIDGET_VERTICLE_GAP * 4)
MainWinLabelA.place(x = X1, y = Y1, width = W1, height = H1)
MainWindow.update()
print("LabelA (Width, Height) = ({:04d}, {:04d})".format(MainWinLabelA.winfo_width(), MainWinLabelA.winfo_height()))
print("LabelA wrt. Scr (X, Y) = ({:04d}, {:04d})".format(MainWinLabelA.winfo_rootx(), MainWinLabelA.winfo_rooty()))
print("LabelA wrt. Win (X, Y) = ({:04d}, {:04d})".format(X1, Y1))
print()

# Tkinter Label widget.
MainWinLabelB = Label(MainWindow, bg = "#F5F5F5", bd = 4, relief = RAISED, text ="")
X2 = MAIN_PIVOT_X + WIDGET_HORIZONTAL_GAP
Y2 = WIDGET_VERTICLE_GAP + H1 + (WIDGET_VERTICLE_GAP * 1)
W2 = MainWindowWidth - (WIDGET_HORIZONTAL_GAP * 2)
# H2 = (MainWindowHeight - (WIDGET_VERTICLE_GAP * 4)) // 2
H2 = (MainWindowHeight - (WIDGET_VERTICLE_GAP * 4)) // 2
H2 = H2 - (WIDGET_VERTICLE_GAP * 4)
MainWinLabelB.place(x = X2, y = Y2, width = W2, height = H2)
MainWindow.update()
print("LabelB (Width, Height) = ({:04d}, {:04d})".format(MainWinLabelB.winfo_width(), MainWinLabelB.winfo_height()))
print("LabelB wrt. Scr (X, Y) = ({:04d}, {:04d})".format(MainWinLabelB.winfo_rootx(), MainWinLabelB.winfo_rooty()))
print("LabelB wrt. Win (X, Y) = ({:04d}, {:04d})".format(X2, Y2))
print()

# Tkinter Label widget.
MainWinLabel01 = Label(MainWindow, text = LABEL01_TITLE, width = 25)
# MainWinLabel01.place(x = 10, y = 10)
# MainWindow.update()
# print(MainWinLabel01.winfo_width(), MainWinLabel01.winfo_height())
# text = "Enter text to predict runbook URL:" width = 25 >> 181
# Default height of Label widget = 21
X3 = (MainWindowWidth - 181) // 2
Y3 = WIDGET_VERTICLE_GAP + WIDGET_VERTICLE_GAP
W3 = 181
H3 = WIDGET_LABEL_HEIGHT
MainWinLabel01.place(x = X3, y = Y3, width = W3, height = H3)
MainWindow.update()
print("Label1 (Width, Height) = ({:04d}, {:04d})".format(MainWinLabel01.winfo_width(), MainWinLabel01.winfo_height()))
print("Label1 wrt. Scr (X, Y) = ({:04d}, {:04d})".format(MainWinLabel01.winfo_rootx(), MainWinLabel01.winfo_rooty()))
print("Label1 wrt. Win (X, Y) = ({:04d}, {:04d})".format(X3, Y3))
print()

# Tkinter Text widget.
MainWinText01 = Text(MainWindow, width = 108, height = 6)
# MainWinSrll01 = Scrollbar(MainWindow)
MainWinSrll01 = Scrollbar(MainWinText01)
MainWinText01.configure(yscrollcommand=MainWinSrll01.set)
MainWinText01.pack(side=LEFT)
MainWinSrll01.config(command=MainWinText01.yview)
MainWinSrll01.pack(side=RIGHT, fill=Y)
# MainWinText01.place(x = 10, y = 10)
# MainWindow.update()
# print(MainWinText01.winfo_width(), MainWinText01.winfo_height())
# width = 108 >> 868
# height = 6 >> 100
X4 = (MainWindowWidth - 868) // 2
Y4 = Y3 + H3 + WIDGET_VERTICLE_GAP
W4 = 868
# H4 = (WIDGET_TEXT_HEIGHT * 5)
# MainWinText01.place(x = X4, y = Y4, width = W4, height = H4)
# MainWinText01.place(x = X4, y = Y4, width = W4, height = 100)
MainWinText01.place(x = X4, y = Y4, width = W4, height = 200)
MainWindow.update()
print("Text1  (Width, Height) = ({:04d}, {:04d})".format(MainWinText01.winfo_width(), MainWinText01.winfo_height()))
print("Text1  wrt. Scr (X, Y) = ({:04d}, {:04d})".format(MainWinText01.winfo_rootx(), MainWinText01.winfo_rooty()))
print("Text1  wrt. Win (X, Y) = ({:04d}, {:04d})".format(X4, Y4))
print()

# Tkinter Button widget.
MainWinButton01 = Button(MainWindow, text = "Submit", command = ModelManager, width = 10)
# MainWinButton01.place(x= 10, y = 10)
# MainWindow.update()
# print(MainWinButton01.winfo_width(), MainWinButton01.winfo_height())
# text = "Submit", width = 10 >> 80
# Default height of Button widget = 26
X5 = (MainWindowWidth - 80) // 2
Y5 = Y4 + MainWinText01.winfo_height() + WIDGET_VERTICLE_GAP
W5 = 80
H5 = WIDGET_BUTTON_HEIGHT
MainWinButton01.place(x = X5, y = Y5, width = W5, height = H5)
MainWindow.update()
print("Buton1 (Width, Height) = ({:04d}, {:04d})".format(MainWinButton01.winfo_width(), MainWinButton01.winfo_height()))
print("Buton1 wrt. Scr (X, Y) = ({:04d}, {:04d})".format(MainWinButton01.winfo_rootx(), MainWinButton01.winfo_rooty()))
print("Buton1 wrt. Win (X, Y) = ({:04d}, {:04d})".format(X5, Y5))
print()

# Tkinter Label widget.
MainWinLabel02 = Label(MainWindow, text = LABEL02_TITLE, width = 17)
# MainWinLabel02.place(x = 10, y = 10)
# MainWindow.update()
# print(MainWinLabel02.winfo_width(), MainWinLabel02.winfo_height())
# text = "Predicted runbook URL:' width = 17 >> 125
# Default height of Label widget = 21
X6 = (MainWindowWidth - 125) // 2
# Y6 = Y5 + H5 + WIDGET_VERTICLE_GAP + WIDGET_VERTICLE_GAP + WIDGET_VERTICLE_GAP
Y6 = 475 - WIDGET_VERTICLE_GAP - WIDGET_ENTRY_HEIGHT - WIDGET_VERTICLE_GAP - WIDGET_LABEL_HEIGHT
W6 = 125
H6 = WIDGET_LABEL_HEIGHT
MainWinLabel02.place(x = X6, y = Y6, width = W6, height = H6)
MainWindow.update()
print("Label2 (Width, Height) = ({:04d}, {:04d})".format(MainWinLabel02.winfo_width(), MainWinLabel02.winfo_height()))
print("Label2 wrt. Scr (X, Y) = ({:04d}, {:04d})".format(MainWinLabel02.winfo_rootx(), MainWinLabel02.winfo_rooty()))
print("Label2 wrt. Win (X, Y) = ({:04d}, {:04d})".format(X6, Y6))
print()

# # Tkinter Text widget.
# MainWinText02 = Text(MainWindow, width = 108, height = 4)
# # MainWinSrll02 = Scrollbar(MainWindow)
# MainWinSrll02 = Scrollbar(MainWinText02)
# MainWinText02.configure(yscrollcommand=MainWinSrll02.set)
# MainWinText02.pack(side=LEFT)
# MainWinSrll02.config(command=MainWinText02.yview)
# MainWinSrll02.pack(side=RIGHT, fill=Y)
# MainWinText02.configure(cursor='arrow', state=DISABLED)
# # MainWinText02.place(x = 10, y = 10)
# # MainWindow.update()
# # print(MainWinText02.winfo_width(), MainWinText02.winfo_height())
# # width = 108 >> 868
# # height = 6 >> 100
# X7 = (MainWindowWidth - 868) // 2
# Y7 = Y6 + H6 + WIDGET_VERTICLE_GAP
# W7 = 868
# MainWinText02.place(x = X7, y = Y7, width = W7, height = 68)
# MainWindow.update()
# print("Text2  (Width, Height) = ({:04d}, {:04d})".format(MainWinText02.winfo_width(), MainWinText02.winfo_height()))
# print("Text2  wrt. Scr (X, Y) = ({:04d}, {:04d})".format(MainWinText02.winfo_rootx(), MainWinText02.winfo_rooty()))
# print("Text2  wrt. Win (X, Y) = ({:04d}, {:04d})".format(X7, Y7))
# print()

# Tkinter Entry widget.
MainWinEntry01 = Entry(MainWindow, width = 55)
# MainWinEntry01.place(x = 10, y = 10)
# MainWindow.update()
# print(MainWinEntry01.winfo_width(), MainWinEntry01.winfo_height())
# text = "This resume is suitable for the position: DataScience Engineer", width = 55 >> 334
# Default height of Entry widget =  19
X7 = (MainWindowWidth - 334) // 2
Y7 = 475 - WIDGET_VERTICLE_GAP - WIDGET_ENTRY_HEIGHT
W7 = 334
H7 = WIDGET_ENTRY_HEIGHT
MainWinEntry01.place(x = X7, y = Y7, width = W7, height = H7)
MainWindow.update()
print("Entry1 (Width, Height) = ({:04d}, {:04d})".format(MainWinEntry01.winfo_width(), MainWinEntry01.winfo_height()))
print("Entry1 wrt. Scr (X, Y) = ({:04d}, {:04d})".format(MainWinEntry01.winfo_rootx(), MainWinEntry01.winfo_rooty()))
print("Entry1 wrt. Win (X, Y) = ({:04d}, {:04d})".format(X7, Y7))
print()

# Tkinter Label widget.
MainWinLabel03 = Label(MainWindow, text = LABEL03_TITLE, width = 21)
# MainWinLabel03.place(x = 10, y = 10)
# MainWindow.update()
# print(MainWinLabel03.winfo_width(), MainWinLabel03.winfo_height())
# text = "Confidence score: 000.00%", width = 21 >> 153
# Default height of Label widget = 21
X8 = (MainWindowWidth - 153) // 2
# Y8 = Y7 + MainWinText02.winfo_height() + int(WIDGET_VERTICLE_GAP * (2/3))
Y8 = 475
W8 = 153
H8 = WIDGET_LABEL_HEIGHT
MainWinLabel03.place(x = X8, y = Y8, width = W8, height = H8)
MainWindow.update()
print("Label3 (Width, Height) = ({:04d}, {:04d})".format(MainWinLabel03.winfo_width(), MainWinLabel03.winfo_height()))
print("Label3 wrt. Scr (X, Y) = ({:04d}, {:04d})".format(MainWinLabel03.winfo_rootx(), MainWinLabel03.winfo_rooty()))
print("Label3 wrt. Win (X, Y) = ({:04d}, {:04d})".format(X8, Y8))
print()

# Create a button to exit the application.
# Tkinter Button widget.
MainFrameButton = Button(MainFrame, text = "Exit", fg = "black", command = ExitCallBack, width = 10)
MainFrameButton.pack(side = BOTTOM)
MainWindow.update()
print("Buton  (Width, Height) = ({:04d}, {:04d})".format(MainFrameButton.winfo_width(), MainFrameButton.winfo_height()))
print("Buton  wrt. Scr (X, Y) = ({:04d}, {:04d})".format(MainFrameButton.winfo_rootx(), MainFrameButton.winfo_rooty()))
print()


# Infinite loop.
# Execution of this Python code halts here.
MainWindow.mainloop()